{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "5272160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config Data Structure\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "from pymongo import MongoClient as mc\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "import pprint as pp\n",
    "import random as ran\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN, LSTM\n",
    "\n",
    "mongo_uri = \"mongodb://localhost:27017\"\n",
    "client = mc(mongo_uri)\n",
    "keti_db = client.keti_pattern_recognition\n",
    "\n",
    "household_col = keti_db.household_info\n",
    "weather_col = keti_db.weather_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "47c1527a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2018-05-01</th>\n",
       "      <th>2018-05-02</th>\n",
       "      <th>2018-05-03</th>\n",
       "      <th>2018-05-04</th>\n",
       "      <th>2018-05-05</th>\n",
       "      <th>2018-05-06</th>\n",
       "      <th>2018-05-07</th>\n",
       "      <th>2018-05-08</th>\n",
       "      <th>2018-05-09</th>\n",
       "      <th>2018-05-10</th>\n",
       "      <th>...</th>\n",
       "      <th>2019-04-21</th>\n",
       "      <th>2019-04-22</th>\n",
       "      <th>2019-04-23</th>\n",
       "      <th>2019-04-24</th>\n",
       "      <th>2019-04-25</th>\n",
       "      <th>2019-04-26</th>\n",
       "      <th>2019-04-27</th>\n",
       "      <th>2019-04-28</th>\n",
       "      <th>2019-04-29</th>\n",
       "      <th>2019-04-30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.341</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.337</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.324</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.319</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.235</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.169</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.171</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.170</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.172</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.199</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.169</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.170</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.215</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.212</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.257</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.203</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.198</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.197</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.196</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.211</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.335</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.306</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.305</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    2018-05-01  2018-05-02  2018-05-03  2018-05-04  2018-05-05  2018-05-06  \\\n",
       "0        0.341       0.275       0.183       0.309       0.305       0.397   \n",
       "1        0.337       0.201       0.235       0.308       0.179       0.409   \n",
       "2        0.324       0.176       0.167       0.309       0.180       0.400   \n",
       "3        0.319       0.210       0.165       0.309       0.172       0.384   \n",
       "4        0.235       0.199       0.163       0.311       0.171       0.276   \n",
       "5        0.169       0.202       0.164       0.217       0.174       0.206   \n",
       "6        0.200       0.199       0.162       0.218       0.169       0.200   \n",
       "7        0.171       0.252       0.173       0.212       0.164       0.199   \n",
       "8        0.170       0.213       0.226       0.242       0.162       0.199   \n",
       "9        0.172       0.173       0.178       0.187       0.166       0.200   \n",
       "10       0.199       0.186       0.167       0.211       0.169       0.198   \n",
       "11       0.169       0.188       0.212       0.209       0.188       0.236   \n",
       "12       0.170       0.171       0.211       0.211       0.196       0.292   \n",
       "13       0.215       0.191       0.203       0.204       0.220       0.321   \n",
       "14       0.212       0.175       0.202       0.183       0.222       0.291   \n",
       "15       0.257       0.168       0.201       0.180       0.352       0.296   \n",
       "16       0.203       0.196       0.178       0.181       0.399       0.516   \n",
       "17       0.198       0.177       0.182       0.206       0.408       0.677   \n",
       "18       0.197       0.218       0.176       0.188       0.419       0.403   \n",
       "19       0.196       0.200       0.167       0.343       0.409       0.400   \n",
       "20       0.211       0.206       0.169       0.330       0.464       0.398   \n",
       "21       0.335       0.202       0.257       0.329       0.419       0.398   \n",
       "22       0.306       0.201       0.303       0.324       0.411       0.375   \n",
       "23       0.305       0.196       0.302       0.334       0.403       0.371   \n",
       "\n",
       "    2018-05-07  2018-05-08  2018-05-09  2018-05-10  ...  2019-04-21  \\\n",
       "0        0.347       0.345       0.312       0.321  ...       0.182   \n",
       "1        0.178       0.272       0.191       0.208  ...       0.209   \n",
       "2        0.173       0.206       0.183       0.203  ...       0.197   \n",
       "3        0.176       0.204       0.173       0.189  ...       0.194   \n",
       "4        0.178       0.173       0.170       0.184  ...       0.046   \n",
       "5        0.182       0.180       0.170       0.172  ...       0.066   \n",
       "6        0.180       0.188       0.207       0.169  ...       0.068   \n",
       "7        0.232       0.179       0.215       0.216  ...       0.049   \n",
       "8        0.221       0.212       0.244       0.169  ...       0.050   \n",
       "9        0.217       0.171       0.204       0.170  ...       0.141   \n",
       "10       0.213       0.173       0.174       0.173  ...       0.059   \n",
       "11       0.212       0.183       0.174       0.174  ...       0.127   \n",
       "12       0.211       0.185       0.180       0.170  ...       0.203   \n",
       "13       0.184       0.179       0.179       0.178  ...       0.140   \n",
       "14       0.183       0.179       0.179       0.181  ...       0.125   \n",
       "15       0.192       0.206       0.177       0.205  ...       0.052   \n",
       "16       0.203       0.208       0.171       0.208  ...       0.064   \n",
       "17       0.187       0.203       0.174       0.208  ...       0.061   \n",
       "18       0.186       0.202       0.173       0.203  ...       0.132   \n",
       "19       0.184       0.270       0.173       0.202  ...       0.258   \n",
       "20       0.199       0.298       0.227       0.203  ...       0.258   \n",
       "21       0.363       0.357       0.396       0.187  ...       0.213   \n",
       "22       0.317       0.287       0.334       0.312  ...       0.183   \n",
       "23       0.343       0.318       0.353       0.257  ...       0.158   \n",
       "\n",
       "    2019-04-22  2019-04-23  2019-04-24  2019-04-25  2019-04-26  2019-04-27  \\\n",
       "0        0.060       0.063       0.066       0.149       0.164       0.130   \n",
       "1        0.038       0.049       0.062       0.052       0.063       0.046   \n",
       "2        0.050       0.041       0.046       0.067       0.065       0.042   \n",
       "3        0.060       0.064       0.051       0.054       0.039       0.060   \n",
       "4        0.054       0.061       0.064       0.041       0.056       0.033   \n",
       "5        0.035       0.035       0.064       0.066       0.063       0.054   \n",
       "6        0.062       0.057       0.047       0.063       0.071       0.059   \n",
       "7        0.060       0.063       0.049       0.039       0.046       0.028   \n",
       "8        0.040       0.046       0.064       0.059       0.062       0.059   \n",
       "9        0.050       0.046       0.063       0.065       0.049       0.047   \n",
       "10       0.060       0.064       0.046       0.183       0.041       0.041   \n",
       "11       0.053       0.056       0.046       0.224       0.063       0.061   \n",
       "12       0.038       0.036       0.065       0.219       0.055       0.092   \n",
       "13       0.061       0.065       0.065       0.192       0.035       0.154   \n",
       "14       0.064       0.065       0.040       0.165       0.063       0.142   \n",
       "15       0.038       0.038       0.055       0.196       0.062       0.132   \n",
       "16       0.055       0.056       0.069       0.094       0.032       0.208   \n",
       "17       0.066       0.065       0.054       0.066       0.057       0.222   \n",
       "18       0.051       0.048       0.045       0.078       0.060       0.211   \n",
       "19       0.042       0.317       0.068       0.089       0.073       0.270   \n",
       "20       0.063       0.208       0.062       0.073       0.347       0.333   \n",
       "21       0.063       0.262       0.038       0.259       0.214       0.249   \n",
       "22       0.035       0.202       0.099       0.243       0.247       0.238   \n",
       "23       0.056       0.081       0.247       0.187       0.211       0.270   \n",
       "\n",
       "    2019-04-28  2019-04-29  2019-04-30  \n",
       "0        0.290       0.056       0.045  \n",
       "1        0.267       0.053       0.044  \n",
       "2        0.244       0.062       0.059  \n",
       "3        0.276       0.063       0.058  \n",
       "4        0.232       0.061       0.033  \n",
       "5        0.135       0.087       0.054  \n",
       "6        0.093       0.050       0.059  \n",
       "7        0.093       0.046       0.049  \n",
       "8        0.066       0.051       0.040  \n",
       "9        0.089       0.060       0.058  \n",
       "10       0.093       0.060       0.056  \n",
       "11       0.072       0.056       0.030  \n",
       "12       0.184       0.042       0.058  \n",
       "13       0.218       0.049       0.060  \n",
       "14       0.167       0.060       0.038  \n",
       "15       0.166       0.060       0.048  \n",
       "16       0.138       0.046       0.062  \n",
       "17       0.179       0.043       0.051  \n",
       "18       0.173       0.125       0.038  \n",
       "19       0.211       0.197       0.061  \n",
       "20       0.208       0.208       0.059  \n",
       "21       0.242       0.239       0.030  \n",
       "22       0.233       0.248       0.056  \n",
       "23       0.072       0.169       0.058  \n",
       "\n",
       "[24 rows x 92 columns]"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TimeSlot In\n",
    "hh_db_datas = household_col.find_one({\"uid\": \"아파트1-104-1206\"})\n",
    "hh_db_datas\n",
    "\n",
    "uid_in, timeslot = hh_db_datas['uid'], hh_db_datas['timeslot']\n",
    "\n",
    "datelist = [\n",
    "    dt.strptime(ts['time'], \"%Y-%m-%d T%H:%M %z\").date()\n",
    "    for ts in timeslot\n",
    "]\n",
    "datelist = list(set(datelist))\n",
    "datelist.sort()\n",
    "\n",
    "ts_datas = {}\n",
    "start_idx = 0\n",
    "end_idx = 96\n",
    "enl = 1\n",
    "\n",
    "for date in datelist:\n",
    "    ts_datas[date] = [ts['power'] *\n",
    "                      enl for ts in timeslot[start_idx:end_idx]]\n",
    "    start_idx = end_idx\n",
    "    end_idx = end_idx + 96\n",
    "\n",
    "ts_datas = pd.DataFrame(ts_datas).T\n",
    "hh_datas = ts_datas.reset_index().copy()\n",
    "\n",
    "hh_datas.rename(columns={\"index\": \"date\"}, inplace=True)\n",
    "hh_datas['date'] = pd.to_datetime(hh_datas['date'])\n",
    "\n",
    "hh_datas.set_index('date', inplace=True)\n",
    "\n",
    "# Merging\n",
    "merge_size = 4\n",
    "merge_datas = pd.DataFrame()\n",
    "for date in hh_datas.index:\n",
    "    merge_ts = []\n",
    "    new_ts_size = round(len(hh_datas.loc[date]) / merge_size)\n",
    "    \n",
    "    for idx in range(0,new_ts_size):\n",
    "        merge_ts.append(\n",
    "            hh_datas.loc[date][merge_size * idx:merge_size * (idx + 1)].sum()\n",
    "        )\n",
    "    merge_datas[date] = merge_ts\n",
    "    \n",
    "def get_season_no(month):\n",
    "    if month in [3,4,5]:\n",
    "        return 1 # 봄\n",
    "    elif month in [6,7,8]:\n",
    "        return 2 # 여름\n",
    "    elif month in [9,10,11]:\n",
    "        return 3 # 가을\n",
    "    elif month in [12,1,2]:\n",
    "        return 4 # 겨울\n",
    "    \n",
    "separate_datas_col = list(filter(lambda data: get_season_no(data.month) == 1, merge_datas.columns))\n",
    "# print(separate_datas_col)\n",
    "merge_datas = merge_datas[separate_datas_col]\n",
    "merge_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "d10d1088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2018-05-01</th>\n",
       "      <th>2019-04-17</th>\n",
       "      <th>2019-04-06</th>\n",
       "      <th>2018-05-20</th>\n",
       "      <th>2019-03-15</th>\n",
       "      <th>2019-04-28</th>\n",
       "      <th>2019-03-23</th>\n",
       "      <th>2019-04-08</th>\n",
       "      <th>2018-05-26</th>\n",
       "      <th>2019-03-09</th>\n",
       "      <th>2019-04-02</th>\n",
       "      <th>2018-05-23</th>\n",
       "      <th>2018-05-24</th>\n",
       "      <th>2018-05-02</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.341</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.337</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.324</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.319</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.235</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.169</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.171</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.170</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.172</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.199</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.169</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.170</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.215</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.212</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.257</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.203</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.198</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.197</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.196</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.211</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.335</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.306</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.305</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    2018-05-01  2019-04-17  2019-04-06  2018-05-20  2019-03-15  2019-04-28  \\\n",
       "0        0.341       0.073       0.065       0.208       0.064       0.290   \n",
       "1        0.337       0.061       0.043       0.208       0.039       0.267   \n",
       "2        0.324       0.037       0.061       0.208       0.052       0.244   \n",
       "3        0.319       0.054       0.060       0.208       0.061       0.276   \n",
       "4        0.235       0.062       0.028       0.208       0.053       0.232   \n",
       "5        0.169       0.050       0.060       0.208       0.037       0.135   \n",
       "6        0.200       0.040       0.058       0.208       0.102       0.093   \n",
       "7        0.171       0.110       0.035       0.208       0.057       0.093   \n",
       "8        0.170       0.059       0.053       0.208       0.038       0.066   \n",
       "9        0.172       0.032       0.059       0.208       0.046       0.089   \n",
       "10       0.199       0.052       0.041       0.208       0.057       0.093   \n",
       "11       0.169       0.059       0.047       0.208       0.051       0.072   \n",
       "12       0.170       0.045       0.060       0.208       0.032       0.184   \n",
       "13       0.215       0.041       0.066       0.208       0.057       0.218   \n",
       "14       0.212       0.060       0.206       0.208       0.057       0.167   \n",
       "15       0.257       0.056       0.195       0.208       0.048       0.166   \n",
       "16       0.203       0.033       0.188       0.208       0.094       0.138   \n",
       "17       0.198       0.061       0.245       0.208       0.059       0.179   \n",
       "18       0.197       0.098       0.284       0.208       0.040       0.173   \n",
       "19       0.196       0.044       0.282       0.208       0.048       0.211   \n",
       "20       0.211       0.046       0.214       0.208       0.058       0.208   \n",
       "21       0.335       0.062       0.200       0.208       0.043       0.242   \n",
       "22       0.306       0.056       0.263       0.208       0.043       0.233   \n",
       "23       0.305       0.123       0.103       0.208       0.057       0.072   \n",
       "\n",
       "    2019-03-23  2019-04-08  2018-05-26  2019-03-09  2019-04-02  2018-05-23  \\\n",
       "0        0.035       0.091       0.310       0.174       0.048       0.257   \n",
       "1        0.064       0.088       0.255       0.089       0.075       0.181   \n",
       "2        0.063       0.107       0.211       0.083       0.078       0.174   \n",
       "3        0.040       0.073       0.207       0.071       0.049       0.171   \n",
       "4        0.049       0.094       0.202       0.097       0.066       0.174   \n",
       "5        0.061       0.100       0.202       0.101       0.073       0.171   \n",
       "6        0.051       0.072       0.172       0.076       0.056       0.172   \n",
       "7        0.039       0.090       0.193       0.112       0.047       0.217   \n",
       "8        0.059       0.097       0.181       0.260       0.057       0.188   \n",
       "9        0.059       0.073       0.176       0.346       0.048       0.189   \n",
       "10       0.037       0.085       0.187       0.226       0.038       0.215   \n",
       "11       0.050       0.094       0.223       0.154       0.057       0.223   \n",
       "12       0.059       0.080       0.322       0.145       0.052       0.218   \n",
       "13       0.083       0.076       0.289       0.201       0.032       0.216   \n",
       "14       0.176       0.093       0.219       0.275       0.057       0.217   \n",
       "15       0.238       0.088       0.187       0.254       0.054       0.188   \n",
       "16       0.312       0.068       0.219       0.243       0.031       0.207   \n",
       "17       0.169       0.094       0.224       0.224       0.142       0.194   \n",
       "18       0.251       0.095       0.226       0.081       0.242       0.187   \n",
       "19       0.362       0.250       0.220       0.093       0.260       0.253   \n",
       "20       0.324       0.300       0.216       0.104       0.260       0.336   \n",
       "21       0.318       0.248       0.215       0.394       0.267       0.413   \n",
       "22       0.250       0.243       0.215       0.463       0.235       0.399   \n",
       "23       0.263       0.098       0.215       0.336       0.229       0.178   \n",
       "\n",
       "    2018-05-24  2018-05-02  \n",
       "0        0.176       0.275  \n",
       "1        0.175       0.201  \n",
       "2        0.211       0.176  \n",
       "3        0.211       0.210  \n",
       "4        0.204       0.199  \n",
       "5        0.202       0.202  \n",
       "6        0.176       0.199  \n",
       "7        0.241       0.252  \n",
       "8        0.175       0.213  \n",
       "9        0.174       0.173  \n",
       "10       0.178       0.186  \n",
       "11       0.184       0.188  \n",
       "12       0.185       0.171  \n",
       "13       0.175       0.191  \n",
       "14       0.177       0.175  \n",
       "15       0.175       0.168  \n",
       "16       0.175       0.196  \n",
       "17       0.176       0.177  \n",
       "18       0.215       0.218  \n",
       "19       0.201       0.200  \n",
       "20       0.206       0.206  \n",
       "21       0.200       0.202  \n",
       "22       0.197       0.201  \n",
       "23       0.197       0.196  "
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set Test Datas\n",
    "# 계절별 10% 랜덤하게\n",
    "def get_season_no(month):\n",
    "    if month in [3,4,5]:\n",
    "        return 1 # 봄\n",
    "    elif month in [6,7,8]:\n",
    "        return 2 # 여름\n",
    "    elif month in [9,10,11]:\n",
    "        return 3 # 가을\n",
    "    elif month in [12,1,2]:\n",
    "        return 4 # 겨울\n",
    "    \n",
    "test_merge_datas = pd.DataFrame();\n",
    "\n",
    "for i in range(1,2):\n",
    "    filter_list = list(filter(lambda date: get_season_no(date.month) == i, merge_datas.columns))\n",
    "    test_list_idx = list()\n",
    "    while True:\n",
    "        filter_data = filter_list[ran.randrange(0,len(filter_list))]\n",
    "        if filter_data not in test_list_idx:\n",
    "            test_list_idx.append(filter_data)\n",
    "            \n",
    "        if len(test_list_idx) >= (len(filter_list) * 15 / 100):\n",
    "            break;\n",
    "    test_merge_datas = pd.concat([test_merge_datas, merge_datas[test_list_idx]], axis=1)\n",
    "    merge_datas.drop(test_list_idx, axis=1, inplace=True)\n",
    "\n",
    "test_merge_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "7588d42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1872\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "merge_datas\n",
    "y = reduce(lambda acc, cur: cur + acc ,merge_datas.values.tolist(), [])\n",
    "value_size = len(y)\n",
    "print(value_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "5ad37657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'눈': 5,\n",
      " '박무': 4,\n",
      " '비': 3,\n",
      " '소나기': 7,\n",
      " '안개': 10,\n",
      " '안개비': 11,\n",
      " '연무': 2,\n",
      " '진눈깨비': 12,\n",
      " '채운': 8,\n",
      " '특이사항 없음': 1,\n",
      " '햇무리': 6,\n",
      " '황사': 9}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>season_no</th>\n",
       "      <th>day_no</th>\n",
       "      <th>weather</th>\n",
       "      <th>weather_no</th>\n",
       "      <th>avg_ta</th>\n",
       "      <th>avg_rhm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>연무</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-05-02</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>비</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-05-03</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>비</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-05-04</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>특이사항 없음</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-05-05</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>특이사항 없음</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-26</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>비</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-27</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>햇무리</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-28</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>비</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>햇무리</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-30</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>햇무리</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  season_no  day_no  weather  weather_no  avg_ta  avg_rhm\n",
       "0  2018-05-01          1       2       연무           2      20       73\n",
       "0  2018-05-02          1       3        비           3      15       90\n",
       "0  2018-05-03          1       4        비           3      11       62\n",
       "0  2018-05-04          1       5  특이사항 없음           1      14       46\n",
       "0  2018-05-05          1       6  특이사항 없음           1      18       47\n",
       "..        ...        ...     ...      ...         ...     ...      ...\n",
       "0  2019-04-26          1       5        비           3       8       82\n",
       "0  2019-04-27          1       6      햇무리           6      12       53\n",
       "0  2019-04-28          1       7        비           3      13       49\n",
       "0  2019-04-29          1       1      햇무리           6      13       53\n",
       "0  2019-04-30          1       2      햇무리           6      16       53\n",
       "\n",
       "[365 rows x 7 columns]"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Config Training Datas\n",
    "wt_db_datas = weather_col.find()\n",
    "wt_datas = pd.DataFrame()\n",
    "for wt in wt_db_datas:\n",
    "    tmp = pd.DataFrame()\n",
    "    tmp['date'] = [wt['date']]\n",
    "    tmp['weather'] = [wt['weather']]\n",
    "    tmp['avg_ta'] = round(float(wt['avgTa']))\n",
    "    tmp['avg_rhm'] = round(float(wt['avgRhm']))\n",
    "    \n",
    "    wt_datas = pd.concat([wt_datas, tmp])\n",
    "\n",
    "# weather 정수 인코딩\n",
    "weather_count = Counter(wt_datas['weather'])\n",
    "weather_integer = dict()\n",
    "rank = 1\n",
    "for key, count in weather_count.most_common():\n",
    "    weather_integer[key] = rank\n",
    "    rank += 1\n",
    "pp.pprint(weather_integer)\n",
    "wt_datas['weather_no'] = [weather_integer[weather] for weather in wt_datas['weather']]\n",
    "wt_datas\n",
    "\n",
    "def get_season_no(month):\n",
    "    if month in [3,4,5]:\n",
    "        return 1 # 봄\n",
    "    elif month in [6,7,8]:\n",
    "        return 2 # 여름\n",
    "    elif month in [9,10,11]:\n",
    "        return 3 # 가을\n",
    "    elif month in [12,1,2]:\n",
    "        return 4 # 겨울\n",
    "    \n",
    "# Date, Season Utils\n",
    "wt_datas['season_no'] = [get_season_no(weather.month) for weather in wt_datas['date']] \n",
    "wt_datas['day_no'] = [weather.weekday() + 1 for weather in wt_datas['date']] \n",
    "\n",
    "sample_weather_col = ['season_no','day_no','weather_no','avg_ta', 'avg_rhm']\n",
    "sample_weather_col_2 = ['date','season_no','day_no','weather','weather_no','avg_ta', 'avg_rhm']\n",
    "wt_datas[sample_weather_col_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "5238e38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples Before Padding Process\n",
      "[list([1, 2, 2, 20, 73, 0.341]) list([1, 2, 2, 20, 73, 0.341, 0.337])\n",
      " list([1, 2, 2, 20, 73, 0.341, 0.337, 0.324])\n",
      " list([1, 2, 2, 20, 73, 0.341, 0.337, 0.324, 0.31900000000000006])\n",
      " list([1, 2, 2, 20, 73, 0.341, 0.337, 0.324, 0.31900000000000006, 0.235])\n",
      " list([1, 2, 2, 20, 73, 0.341, 0.337, 0.324, 0.31900000000000006, 0.235, 0.169])\n",
      " list([1, 2, 2, 20, 73, 0.341, 0.337, 0.324, 0.31900000000000006, 0.235, 0.169, 0.2])\n",
      " list([1, 2, 2, 20, 73, 0.341, 0.337, 0.324, 0.31900000000000006, 0.235, 0.169, 0.2, 0.17099999999999999])\n",
      " list([1, 2, 2, 20, 73, 0.341, 0.337, 0.324, 0.31900000000000006, 0.235, 0.169, 0.2, 0.17099999999999999, 0.16999999999999998])\n",
      " list([1, 2, 2, 20, 73, 0.341, 0.337, 0.324, 0.31900000000000006, 0.235, 0.169, 0.2, 0.17099999999999999, 0.16999999999999998, 0.17200000000000001])\n",
      " list([1, 2, 2, 20, 73, 0.341, 0.337, 0.324, 0.31900000000000006, 0.235, 0.169, 0.2, 0.17099999999999999, 0.16999999999999998, 0.17200000000000001, 0.199])\n",
      " list([1, 2, 2, 20, 73, 0.341, 0.337, 0.324, 0.31900000000000006, 0.235, 0.169, 0.2, 0.17099999999999999, 0.16999999999999998, 0.17200000000000001, 0.199, 0.16899999999999998])\n",
      " list([1, 2, 2, 20, 73, 0.341, 0.337, 0.324, 0.31900000000000006, 0.235, 0.169, 0.2, 0.17099999999999999, 0.16999999999999998, 0.17200000000000001, 0.199, 0.16899999999999998, 0.17])\n",
      " list([1, 2, 2, 20, 73, 0.341, 0.337, 0.324, 0.31900000000000006, 0.235, 0.169, 0.2, 0.17099999999999999, 0.16999999999999998, 0.17200000000000001, 0.199, 0.16899999999999998, 0.17, 0.215])\n",
      " list([1, 2, 2, 20, 73, 0.341, 0.337, 0.324, 0.31900000000000006, 0.235, 0.169, 0.2, 0.17099999999999999, 0.16999999999999998, 0.17200000000000001, 0.199, 0.16899999999999998, 0.17, 0.215, 0.212])\n",
      " list([1, 2, 2, 20, 73, 0.341, 0.337, 0.324, 0.31900000000000006, 0.235, 0.169, 0.2, 0.17099999999999999, 0.16999999999999998, 0.17200000000000001, 0.199, 0.16899999999999998, 0.17, 0.215, 0.212, 0.257])\n",
      " list([1, 2, 2, 20, 73, 0.341, 0.337, 0.324, 0.31900000000000006, 0.235, 0.169, 0.2, 0.17099999999999999, 0.16999999999999998, 0.17200000000000001, 0.199, 0.16899999999999998, 0.17, 0.215, 0.212, 0.257, 0.20299999999999999])\n",
      " list([1, 2, 2, 20, 73, 0.341, 0.337, 0.324, 0.31900000000000006, 0.235, 0.169, 0.2, 0.17099999999999999, 0.16999999999999998, 0.17200000000000001, 0.199, 0.16899999999999998, 0.17, 0.215, 0.212, 0.257, 0.20299999999999999, 0.198])\n",
      " list([1, 2, 2, 20, 73, 0.341, 0.337, 0.324, 0.31900000000000006, 0.235, 0.169, 0.2, 0.17099999999999999, 0.16999999999999998, 0.17200000000000001, 0.199, 0.16899999999999998, 0.17, 0.215, 0.212, 0.257, 0.20299999999999999, 0.198, 0.197])\n",
      " list([1, 2, 2, 20, 73, 0.341, 0.337, 0.324, 0.31900000000000006, 0.235, 0.169, 0.2, 0.17099999999999999, 0.16999999999999998, 0.17200000000000001, 0.199, 0.16899999999999998, 0.17, 0.215, 0.212, 0.257, 0.20299999999999999, 0.198, 0.197, 0.196])\n",
      " list([1, 2, 2, 20, 73, 0.341, 0.337, 0.324, 0.31900000000000006, 0.235, 0.169, 0.2, 0.17099999999999999, 0.16999999999999998, 0.17200000000000001, 0.199, 0.16899999999999998, 0.17, 0.215, 0.212, 0.257, 0.20299999999999999, 0.198, 0.197, 0.196, 0.21100000000000002])\n",
      " list([1, 2, 2, 20, 73, 0.341, 0.337, 0.324, 0.31900000000000006, 0.235, 0.169, 0.2, 0.17099999999999999, 0.16999999999999998, 0.17200000000000001, 0.199, 0.16899999999999998, 0.17, 0.215, 0.212, 0.257, 0.20299999999999999, 0.198, 0.197, 0.196, 0.21100000000000002, 0.335])\n",
      " list([1, 2, 2, 20, 73, 0.341, 0.337, 0.324, 0.31900000000000006, 0.235, 0.169, 0.2, 0.17099999999999999, 0.16999999999999998, 0.17200000000000001, 0.199, 0.16899999999999998, 0.17, 0.215, 0.212, 0.257, 0.20299999999999999, 0.198, 0.197, 0.196, 0.21100000000000002, 0.335, 0.30600000000000005])\n",
      " list([1, 2, 2, 20, 73, 0.341, 0.337, 0.324, 0.31900000000000006, 0.235, 0.169, 0.2, 0.17099999999999999, 0.16999999999999998, 0.17200000000000001, 0.199, 0.16899999999999998, 0.17, 0.215, 0.212, 0.257, 0.20299999999999999, 0.198, 0.197, 0.196, 0.21100000000000002, 0.335, 0.30600000000000005, 0.30500000000000005])\n",
      " list([1, 3, 1, 15, 38, 0.07300000000000001])\n",
      " list([1, 3, 1, 15, 38, 0.07300000000000001, 0.061])\n",
      " list([1, 3, 1, 15, 38, 0.07300000000000001, 0.061, 0.037])\n",
      " list([1, 3, 1, 15, 38, 0.07300000000000001, 0.061, 0.037, 0.054])\n",
      " list([1, 3, 1, 15, 38, 0.07300000000000001, 0.061, 0.037, 0.054, 0.062])\n",
      " list([1, 3, 1, 15, 38, 0.07300000000000001, 0.061, 0.037, 0.054, 0.062, 0.05])\n",
      " list([1, 3, 1, 15, 38, 0.07300000000000001, 0.061, 0.037, 0.054, 0.062, 0.05, 0.04])\n",
      " list([1, 3, 1, 15, 38, 0.07300000000000001, 0.061, 0.037, 0.054, 0.062, 0.05, 0.04, 0.11])\n",
      " list([1, 3, 1, 15, 38, 0.07300000000000001, 0.061, 0.037, 0.054, 0.062, 0.05, 0.04, 0.11, 0.059000000000000004])\n",
      " list([1, 3, 1, 15, 38, 0.07300000000000001, 0.061, 0.037, 0.054, 0.062, 0.05, 0.04, 0.11, 0.059000000000000004, 0.032])\n",
      " list([1, 3, 1, 15, 38, 0.07300000000000001, 0.061, 0.037, 0.054, 0.062, 0.05, 0.04, 0.11, 0.059000000000000004, 0.032, 0.052])\n",
      " list([1, 3, 1, 15, 38, 0.07300000000000001, 0.061, 0.037, 0.054, 0.062, 0.05, 0.04, 0.11, 0.059000000000000004, 0.032, 0.052, 0.059000000000000004])\n",
      " list([1, 3, 1, 15, 38, 0.07300000000000001, 0.061, 0.037, 0.054, 0.062, 0.05, 0.04, 0.11, 0.059000000000000004, 0.032, 0.052, 0.059000000000000004, 0.045])\n",
      " list([1, 3, 1, 15, 38, 0.07300000000000001, 0.061, 0.037, 0.054, 0.062, 0.05, 0.04, 0.11, 0.059000000000000004, 0.032, 0.052, 0.059000000000000004, 0.045, 0.041])\n",
      " list([1, 3, 1, 15, 38, 0.07300000000000001, 0.061, 0.037, 0.054, 0.062, 0.05, 0.04, 0.11, 0.059000000000000004, 0.032, 0.052, 0.059000000000000004, 0.045, 0.041, 0.06])\n",
      " list([1, 3, 1, 15, 38, 0.07300000000000001, 0.061, 0.037, 0.054, 0.062, 0.05, 0.04, 0.11, 0.059000000000000004, 0.032, 0.052, 0.059000000000000004, 0.045, 0.041, 0.06, 0.056])\n",
      " list([1, 3, 1, 15, 38, 0.07300000000000001, 0.061, 0.037, 0.054, 0.062, 0.05, 0.04, 0.11, 0.059000000000000004, 0.032, 0.052, 0.059000000000000004, 0.045, 0.041, 0.06, 0.056, 0.033])\n",
      " list([1, 3, 1, 15, 38, 0.07300000000000001, 0.061, 0.037, 0.054, 0.062, 0.05, 0.04, 0.11, 0.059000000000000004, 0.032, 0.052, 0.059000000000000004, 0.045, 0.041, 0.06, 0.056, 0.033, 0.061])\n",
      " list([1, 3, 1, 15, 38, 0.07300000000000001, 0.061, 0.037, 0.054, 0.062, 0.05, 0.04, 0.11, 0.059000000000000004, 0.032, 0.052, 0.059000000000000004, 0.045, 0.041, 0.06, 0.056, 0.033, 0.061, 0.098])\n",
      " list([1, 3, 1, 15, 38, 0.07300000000000001, 0.061, 0.037, 0.054, 0.062, 0.05, 0.04, 0.11, 0.059000000000000004, 0.032, 0.052, 0.059000000000000004, 0.045, 0.041, 0.06, 0.056, 0.033, 0.061, 0.098, 0.044])\n",
      " list([1, 3, 1, 15, 38, 0.07300000000000001, 0.061, 0.037, 0.054, 0.062, 0.05, 0.04, 0.11, 0.059000000000000004, 0.032, 0.052, 0.059000000000000004, 0.045, 0.041, 0.06, 0.056, 0.033, 0.061, 0.098, 0.044, 0.046])\n",
      " list([1, 3, 1, 15, 38, 0.07300000000000001, 0.061, 0.037, 0.054, 0.062, 0.05, 0.04, 0.11, 0.059000000000000004, 0.032, 0.052, 0.059000000000000004, 0.045, 0.041, 0.06, 0.056, 0.033, 0.061, 0.098, 0.044, 0.046, 0.062000000000000006])\n",
      " list([1, 3, 1, 15, 38, 0.07300000000000001, 0.061, 0.037, 0.054, 0.062, 0.05, 0.04, 0.11, 0.059000000000000004, 0.032, 0.052, 0.059000000000000004, 0.045, 0.041, 0.06, 0.056, 0.033, 0.061, 0.098, 0.044, 0.046, 0.062000000000000006, 0.056])\n",
      " list([1, 3, 1, 15, 38, 0.07300000000000001, 0.061, 0.037, 0.054, 0.062, 0.05, 0.04, 0.11, 0.059000000000000004, 0.032, 0.052, 0.059000000000000004, 0.045, 0.041, 0.06, 0.056, 0.033, 0.061, 0.098, 0.044, 0.046, 0.062000000000000006, 0.056, 0.123])\n",
      " list([1, 6, 3, 9, 40, 0.065])\n",
      " list([1, 6, 3, 9, 40, 0.065, 0.043000000000000003])\n",
      " list([1, 6, 3, 9, 40, 0.065, 0.043000000000000003, 0.061])\n",
      " list([1, 6, 3, 9, 40, 0.065, 0.043000000000000003, 0.061, 0.06])\n",
      " list([1, 6, 3, 9, 40, 0.065, 0.043000000000000003, 0.061, 0.06, 0.028])\n",
      " list([1, 6, 3, 9, 40, 0.065, 0.043000000000000003, 0.061, 0.06, 0.028, 0.06])\n",
      " list([1, 6, 3, 9, 40, 0.065, 0.043000000000000003, 0.061, 0.06, 0.028, 0.06, 0.058])\n",
      " list([1, 6, 3, 9, 40, 0.065, 0.043000000000000003, 0.061, 0.06, 0.028, 0.06, 0.058, 0.034999999999999996])\n",
      " list([1, 6, 3, 9, 40, 0.065, 0.043000000000000003, 0.061, 0.06, 0.028, 0.06, 0.058, 0.034999999999999996, 0.053])\n",
      " list([1, 6, 3, 9, 40, 0.065, 0.043000000000000003, 0.061, 0.06, 0.028, 0.06, 0.058, 0.034999999999999996, 0.053, 0.059])\n",
      " list([1, 6, 3, 9, 40, 0.065, 0.043000000000000003, 0.061, 0.06, 0.028, 0.06, 0.058, 0.034999999999999996, 0.053, 0.059, 0.040999999999999995])\n",
      " list([1, 6, 3, 9, 40, 0.065, 0.043000000000000003, 0.061, 0.06, 0.028, 0.06, 0.058, 0.034999999999999996, 0.053, 0.059, 0.040999999999999995, 0.047])\n",
      " list([1, 6, 3, 9, 40, 0.065, 0.043000000000000003, 0.061, 0.06, 0.028, 0.06, 0.058, 0.034999999999999996, 0.053, 0.059, 0.040999999999999995, 0.047, 0.06])\n",
      " list([1, 6, 3, 9, 40, 0.065, 0.043000000000000003, 0.061, 0.06, 0.028, 0.06, 0.058, 0.034999999999999996, 0.053, 0.059, 0.040999999999999995, 0.047, 0.06, 0.066])\n",
      " list([1, 6, 3, 9, 40, 0.065, 0.043000000000000003, 0.061, 0.06, 0.028, 0.06, 0.058, 0.034999999999999996, 0.053, 0.059, 0.040999999999999995, 0.047, 0.06, 0.066, 0.20600000000000002])\n",
      " list([1, 6, 3, 9, 40, 0.065, 0.043000000000000003, 0.061, 0.06, 0.028, 0.06, 0.058, 0.034999999999999996, 0.053, 0.059, 0.040999999999999995, 0.047, 0.06, 0.066, 0.20600000000000002, 0.195])\n",
      " list([1, 6, 3, 9, 40, 0.065, 0.043000000000000003, 0.061, 0.06, 0.028, 0.06, 0.058, 0.034999999999999996, 0.053, 0.059, 0.040999999999999995, 0.047, 0.06, 0.066, 0.20600000000000002, 0.195, 0.188])\n",
      " list([1, 6, 3, 9, 40, 0.065, 0.043000000000000003, 0.061, 0.06, 0.028, 0.06, 0.058, 0.034999999999999996, 0.053, 0.059, 0.040999999999999995, 0.047, 0.06, 0.066, 0.20600000000000002, 0.195, 0.188, 0.245])\n",
      " list([1, 6, 3, 9, 40, 0.065, 0.043000000000000003, 0.061, 0.06, 0.028, 0.06, 0.058, 0.034999999999999996, 0.053, 0.059, 0.040999999999999995, 0.047, 0.06, 0.066, 0.20600000000000002, 0.195, 0.188, 0.245, 0.28400000000000003])\n",
      " list([1, 6, 3, 9, 40, 0.065, 0.043000000000000003, 0.061, 0.06, 0.028, 0.06, 0.058, 0.034999999999999996, 0.053, 0.059, 0.040999999999999995, 0.047, 0.06, 0.066, 0.20600000000000002, 0.195, 0.188, 0.245, 0.28400000000000003, 0.28200000000000003])\n",
      " list([1, 6, 3, 9, 40, 0.065, 0.043000000000000003, 0.061, 0.06, 0.028, 0.06, 0.058, 0.034999999999999996, 0.053, 0.059, 0.040999999999999995, 0.047, 0.06, 0.066, 0.20600000000000002, 0.195, 0.188, 0.245, 0.28400000000000003, 0.28200000000000003, 0.21399999999999997])\n",
      " list([1, 6, 3, 9, 40, 0.065, 0.043000000000000003, 0.061, 0.06, 0.028, 0.06, 0.058, 0.034999999999999996, 0.053, 0.059, 0.040999999999999995, 0.047, 0.06, 0.066, 0.20600000000000002, 0.195, 0.188, 0.245, 0.28400000000000003, 0.28200000000000003, 0.21399999999999997, 0.2])\n",
      " list([1, 6, 3, 9, 40, 0.065, 0.043000000000000003, 0.061, 0.06, 0.028, 0.06, 0.058, 0.034999999999999996, 0.053, 0.059, 0.040999999999999995, 0.047, 0.06, 0.066, 0.20600000000000002, 0.195, 0.188, 0.245, 0.28400000000000003, 0.28200000000000003, 0.21399999999999997, 0.2, 0.263])\n",
      " list([1, 6, 3, 9, 40, 0.065, 0.043000000000000003, 0.061, 0.06, 0.028, 0.06, 0.058, 0.034999999999999996, 0.053, 0.059, 0.040999999999999995, 0.047, 0.06, 0.066, 0.20600000000000002, 0.195, 0.188, 0.245, 0.28400000000000003, 0.28200000000000003, 0.21399999999999997, 0.2, 0.263, 0.10300000000000001])\n",
      " list([1, 7, 1, 17, 32, 0.208]) list([1, 7, 1, 17, 32, 0.208, 0.208])\n",
      " list([1, 7, 1, 17, 32, 0.208, 0.208, 0.208])\n",
      " list([1, 7, 1, 17, 32, 0.208, 0.208, 0.208, 0.208])\n",
      " list([1, 7, 1, 17, 32, 0.208, 0.208, 0.208, 0.208, 0.208])\n",
      " list([1, 7, 1, 17, 32, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208])\n",
      " list([1, 7, 1, 17, 32, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208])\n",
      " list([1, 7, 1, 17, 32, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208])\n",
      " list([1, 7, 1, 17, 32, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208])\n",
      " list([1, 7, 1, 17, 32, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208])\n",
      " list([1, 7, 1, 17, 32, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208])\n",
      " list([1, 7, 1, 17, 32, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208])\n",
      " list([1, 7, 1, 17, 32, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208])\n",
      " list([1, 7, 1, 17, 32, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208])\n",
      " list([1, 7, 1, 17, 32, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208])\n",
      " list([1, 7, 1, 17, 32, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208])\n",
      " list([1, 7, 1, 17, 32, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208])\n",
      " list([1, 7, 1, 17, 32, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208])\n",
      " list([1, 7, 1, 17, 32, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208])\n",
      " list([1, 7, 1, 17, 32, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208])\n",
      " list([1, 7, 1, 17, 32, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208])\n",
      " list([1, 7, 1, 17, 32, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208])\n",
      " list([1, 7, 1, 17, 32, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208])\n",
      " list([1, 7, 1, 17, 32, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208, 0.208])\n",
      " list([1, 5, 4, 6, 73, 0.064]) list([1, 5, 4, 6, 73, 0.064, 0.039])\n",
      " list([1, 5, 4, 6, 73, 0.064, 0.039, 0.052])\n",
      " list([1, 5, 4, 6, 73, 0.064, 0.039, 0.052, 0.061])\n",
      " list([1, 5, 4, 6, 73, 0.064, 0.039, 0.052, 0.061, 0.053])\n",
      " list([1, 5, 4, 6, 73, 0.064, 0.039, 0.052, 0.061, 0.053, 0.037])\n",
      " list([1, 5, 4, 6, 73, 0.064, 0.039, 0.052, 0.061, 0.053, 0.037, 0.10200000000000001])\n",
      " list([1, 5, 4, 6, 73, 0.064, 0.039, 0.052, 0.061, 0.053, 0.037, 0.10200000000000001, 0.057])\n",
      " list([1, 5, 4, 6, 73, 0.064, 0.039, 0.052, 0.061, 0.053, 0.037, 0.10200000000000001, 0.057, 0.038])\n",
      " list([1, 5, 4, 6, 73, 0.064, 0.039, 0.052, 0.061, 0.053, 0.037, 0.10200000000000001, 0.057, 0.038, 0.046])\n",
      " list([1, 5, 4, 6, 73, 0.064, 0.039, 0.052, 0.061, 0.053, 0.037, 0.10200000000000001, 0.057, 0.038, 0.046, 0.057])\n",
      " list([1, 5, 4, 6, 73, 0.064, 0.039, 0.052, 0.061, 0.053, 0.037, 0.10200000000000001, 0.057, 0.038, 0.046, 0.057, 0.051000000000000004])\n",
      " list([1, 5, 4, 6, 73, 0.064, 0.039, 0.052, 0.061, 0.053, 0.037, 0.10200000000000001, 0.057, 0.038, 0.046, 0.057, 0.051000000000000004, 0.032])\n",
      " list([1, 5, 4, 6, 73, 0.064, 0.039, 0.052, 0.061, 0.053, 0.037, 0.10200000000000001, 0.057, 0.038, 0.046, 0.057, 0.051000000000000004, 0.032, 0.056999999999999995])\n",
      " list([1, 5, 4, 6, 73, 0.064, 0.039, 0.052, 0.061, 0.053, 0.037, 0.10200000000000001, 0.057, 0.038, 0.046, 0.057, 0.051000000000000004, 0.032, 0.056999999999999995, 0.056999999999999995])\n",
      " list([1, 5, 4, 6, 73, 0.064, 0.039, 0.052, 0.061, 0.053, 0.037, 0.10200000000000001, 0.057, 0.038, 0.046, 0.057, 0.051000000000000004, 0.032, 0.056999999999999995, 0.056999999999999995, 0.048])\n",
      " list([1, 5, 4, 6, 73, 0.064, 0.039, 0.052, 0.061, 0.053, 0.037, 0.10200000000000001, 0.057, 0.038, 0.046, 0.057, 0.051000000000000004, 0.032, 0.056999999999999995, 0.056999999999999995, 0.048, 0.09400000000000001])\n",
      " list([1, 5, 4, 6, 73, 0.064, 0.039, 0.052, 0.061, 0.053, 0.037, 0.10200000000000001, 0.057, 0.038, 0.046, 0.057, 0.051000000000000004, 0.032, 0.056999999999999995, 0.056999999999999995, 0.048, 0.09400000000000001, 0.059])\n",
      " list([1, 5, 4, 6, 73, 0.064, 0.039, 0.052, 0.061, 0.053, 0.037, 0.10200000000000001, 0.057, 0.038, 0.046, 0.057, 0.051000000000000004, 0.032, 0.056999999999999995, 0.056999999999999995, 0.048, 0.09400000000000001, 0.059, 0.039999999999999994])\n",
      " list([1, 5, 4, 6, 73, 0.064, 0.039, 0.052, 0.061, 0.053, 0.037, 0.10200000000000001, 0.057, 0.038, 0.046, 0.057, 0.051000000000000004, 0.032, 0.056999999999999995, 0.056999999999999995, 0.048, 0.09400000000000001, 0.059, 0.039999999999999994, 0.048])\n",
      " list([1, 5, 4, 6, 73, 0.064, 0.039, 0.052, 0.061, 0.053, 0.037, 0.10200000000000001, 0.057, 0.038, 0.046, 0.057, 0.051000000000000004, 0.032, 0.056999999999999995, 0.056999999999999995, 0.048, 0.09400000000000001, 0.059, 0.039999999999999994, 0.048, 0.058])\n",
      " list([1, 5, 4, 6, 73, 0.064, 0.039, 0.052, 0.061, 0.053, 0.037, 0.10200000000000001, 0.057, 0.038, 0.046, 0.057, 0.051000000000000004, 0.032, 0.056999999999999995, 0.056999999999999995, 0.048, 0.09400000000000001, 0.059, 0.039999999999999994, 0.048, 0.058, 0.043])\n",
      " list([1, 5, 4, 6, 73, 0.064, 0.039, 0.052, 0.061, 0.053, 0.037, 0.10200000000000001, 0.057, 0.038, 0.046, 0.057, 0.051000000000000004, 0.032, 0.056999999999999995, 0.056999999999999995, 0.048, 0.09400000000000001, 0.059, 0.039999999999999994, 0.048, 0.058, 0.043, 0.043])\n",
      " list([1, 5, 4, 6, 73, 0.064, 0.039, 0.052, 0.061, 0.053, 0.037, 0.10200000000000001, 0.057, 0.038, 0.046, 0.057, 0.051000000000000004, 0.032, 0.056999999999999995, 0.056999999999999995, 0.048, 0.09400000000000001, 0.059, 0.039999999999999994, 0.048, 0.058, 0.043, 0.043, 0.057])\n",
      " list([1, 7, 3, 13, 49, 0.29000000000000004])\n",
      " list([1, 7, 3, 13, 49, 0.29000000000000004, 0.267])\n",
      " list([1, 7, 3, 13, 49, 0.29000000000000004, 0.267, 0.244])\n",
      " list([1, 7, 3, 13, 49, 0.29000000000000004, 0.267, 0.244, 0.276])\n",
      " list([1, 7, 3, 13, 49, 0.29000000000000004, 0.267, 0.244, 0.276, 0.23199999999999998])\n",
      " list([1, 7, 3, 13, 49, 0.29000000000000004, 0.267, 0.244, 0.276, 0.23199999999999998, 0.135])\n",
      " list([1, 7, 3, 13, 49, 0.29000000000000004, 0.267, 0.244, 0.276, 0.23199999999999998, 0.135, 0.093])\n",
      " list([1, 7, 3, 13, 49, 0.29000000000000004, 0.267, 0.244, 0.276, 0.23199999999999998, 0.135, 0.093, 0.093])\n",
      " list([1, 7, 3, 13, 49, 0.29000000000000004, 0.267, 0.244, 0.276, 0.23199999999999998, 0.135, 0.093, 0.093, 0.066])\n",
      " list([1, 7, 3, 13, 49, 0.29000000000000004, 0.267, 0.244, 0.276, 0.23199999999999998, 0.135, 0.093, 0.093, 0.066, 0.08900000000000001])\n",
      " list([1, 7, 3, 13, 49, 0.29000000000000004, 0.267, 0.244, 0.276, 0.23199999999999998, 0.135, 0.093, 0.093, 0.066, 0.08900000000000001, 0.093])\n",
      " list([1, 7, 3, 13, 49, 0.29000000000000004, 0.267, 0.244, 0.276, 0.23199999999999998, 0.135, 0.093, 0.093, 0.066, 0.08900000000000001, 0.093, 0.072])\n",
      " list([1, 7, 3, 13, 49, 0.29000000000000004, 0.267, 0.244, 0.276, 0.23199999999999998, 0.135, 0.093, 0.093, 0.066, 0.08900000000000001, 0.093, 0.072, 0.184])\n",
      " list([1, 7, 3, 13, 49, 0.29000000000000004, 0.267, 0.244, 0.276, 0.23199999999999998, 0.135, 0.093, 0.093, 0.066, 0.08900000000000001, 0.093, 0.072, 0.184, 0.218])\n",
      " list([1, 7, 3, 13, 49, 0.29000000000000004, 0.267, 0.244, 0.276, 0.23199999999999998, 0.135, 0.093, 0.093, 0.066, 0.08900000000000001, 0.093, 0.072, 0.184, 0.218, 0.16699999999999998])\n",
      " list([1, 7, 3, 13, 49, 0.29000000000000004, 0.267, 0.244, 0.276, 0.23199999999999998, 0.135, 0.093, 0.093, 0.066, 0.08900000000000001, 0.093, 0.072, 0.184, 0.218, 0.16699999999999998, 0.166])\n",
      " list([1, 7, 3, 13, 49, 0.29000000000000004, 0.267, 0.244, 0.276, 0.23199999999999998, 0.135, 0.093, 0.093, 0.066, 0.08900000000000001, 0.093, 0.072, 0.184, 0.218, 0.16699999999999998, 0.166, 0.13799999999999998])\n",
      " list([1, 7, 3, 13, 49, 0.29000000000000004, 0.267, 0.244, 0.276, 0.23199999999999998, 0.135, 0.093, 0.093, 0.066, 0.08900000000000001, 0.093, 0.072, 0.184, 0.218, 0.16699999999999998, 0.166, 0.13799999999999998, 0.17900000000000002])\n",
      " list([1, 7, 3, 13, 49, 0.29000000000000004, 0.267, 0.244, 0.276, 0.23199999999999998, 0.135, 0.093, 0.093, 0.066, 0.08900000000000001, 0.093, 0.072, 0.184, 0.218, 0.16699999999999998, 0.166, 0.13799999999999998, 0.17900000000000002, 0.17300000000000001])\n",
      " list([1, 7, 3, 13, 49, 0.29000000000000004, 0.267, 0.244, 0.276, 0.23199999999999998, 0.135, 0.093, 0.093, 0.066, 0.08900000000000001, 0.093, 0.072, 0.184, 0.218, 0.16699999999999998, 0.166, 0.13799999999999998, 0.17900000000000002, 0.17300000000000001, 0.211])\n",
      " list([1, 7, 3, 13, 49, 0.29000000000000004, 0.267, 0.244, 0.276, 0.23199999999999998, 0.135, 0.093, 0.093, 0.066, 0.08900000000000001, 0.093, 0.072, 0.184, 0.218, 0.16699999999999998, 0.166, 0.13799999999999998, 0.17900000000000002, 0.17300000000000001, 0.211, 0.20800000000000002])\n",
      " list([1, 7, 3, 13, 49, 0.29000000000000004, 0.267, 0.244, 0.276, 0.23199999999999998, 0.135, 0.093, 0.093, 0.066, 0.08900000000000001, 0.093, 0.072, 0.184, 0.218, 0.16699999999999998, 0.166, 0.13799999999999998, 0.17900000000000002, 0.17300000000000001, 0.211, 0.20800000000000002, 0.242])\n",
      " list([1, 7, 3, 13, 49, 0.29000000000000004, 0.267, 0.244, 0.276, 0.23199999999999998, 0.135, 0.093, 0.093, 0.066, 0.08900000000000001, 0.093, 0.072, 0.184, 0.218, 0.16699999999999998, 0.166, 0.13799999999999998, 0.17900000000000002, 0.17300000000000001, 0.211, 0.20800000000000002, 0.242, 0.23299999999999998])\n",
      " list([1, 7, 3, 13, 49, 0.29000000000000004, 0.267, 0.244, 0.276, 0.23199999999999998, 0.135, 0.093, 0.093, 0.066, 0.08900000000000001, 0.093, 0.072, 0.184, 0.218, 0.16699999999999998, 0.166, 0.13799999999999998, 0.17900000000000002, 0.17300000000000001, 0.211, 0.20800000000000002, 0.242, 0.23299999999999998, 0.07200000000000001])\n",
      " list([1, 6, 12, 3, 47, 0.035]) list([1, 6, 12, 3, 47, 0.035, 0.064])\n",
      " list([1, 6, 12, 3, 47, 0.035, 0.064, 0.063])\n",
      " list([1, 6, 12, 3, 47, 0.035, 0.064, 0.063, 0.04])\n",
      " list([1, 6, 12, 3, 47, 0.035, 0.064, 0.063, 0.04, 0.048999999999999995])\n",
      " list([1, 6, 12, 3, 47, 0.035, 0.064, 0.063, 0.04, 0.048999999999999995, 0.061])\n",
      " list([1, 6, 12, 3, 47, 0.035, 0.064, 0.063, 0.04, 0.048999999999999995, 0.061, 0.051000000000000004])\n",
      " list([1, 6, 12, 3, 47, 0.035, 0.064, 0.063, 0.04, 0.048999999999999995, 0.061, 0.051000000000000004, 0.039])\n",
      " list([1, 6, 12, 3, 47, 0.035, 0.064, 0.063, 0.04, 0.048999999999999995, 0.061, 0.051000000000000004, 0.039, 0.059])\n",
      " list([1, 6, 12, 3, 47, 0.035, 0.064, 0.063, 0.04, 0.048999999999999995, 0.061, 0.051000000000000004, 0.039, 0.059, 0.059])\n",
      " list([1, 6, 12, 3, 47, 0.035, 0.064, 0.063, 0.04, 0.048999999999999995, 0.061, 0.051000000000000004, 0.039, 0.059, 0.059, 0.037000000000000005])\n",
      " list([1, 6, 12, 3, 47, 0.035, 0.064, 0.063, 0.04, 0.048999999999999995, 0.061, 0.051000000000000004, 0.039, 0.059, 0.059, 0.037000000000000005, 0.05])\n",
      " list([1, 6, 12, 3, 47, 0.035, 0.064, 0.063, 0.04, 0.048999999999999995, 0.061, 0.051000000000000004, 0.039, 0.059, 0.059, 0.037000000000000005, 0.05, 0.059000000000000004])\n",
      " list([1, 6, 12, 3, 47, 0.035, 0.064, 0.063, 0.04, 0.048999999999999995, 0.061, 0.051000000000000004, 0.039, 0.059, 0.059, 0.037000000000000005, 0.05, 0.059000000000000004, 0.08299999999999999])\n",
      " list([1, 6, 12, 3, 47, 0.035, 0.064, 0.063, 0.04, 0.048999999999999995, 0.061, 0.051000000000000004, 0.039, 0.059, 0.059, 0.037000000000000005, 0.05, 0.059000000000000004, 0.08299999999999999, 0.176])\n",
      " list([1, 6, 12, 3, 47, 0.035, 0.064, 0.063, 0.04, 0.048999999999999995, 0.061, 0.051000000000000004, 0.039, 0.059, 0.059, 0.037000000000000005, 0.05, 0.059000000000000004, 0.08299999999999999, 0.176, 0.238])\n",
      " list([1, 6, 12, 3, 47, 0.035, 0.064, 0.063, 0.04, 0.048999999999999995, 0.061, 0.051000000000000004, 0.039, 0.059, 0.059, 0.037000000000000005, 0.05, 0.059000000000000004, 0.08299999999999999, 0.176, 0.238, 0.312])\n",
      " list([1, 6, 12, 3, 47, 0.035, 0.064, 0.063, 0.04, 0.048999999999999995, 0.061, 0.051000000000000004, 0.039, 0.059, 0.059, 0.037000000000000005, 0.05, 0.059000000000000004, 0.08299999999999999, 0.176, 0.238, 0.312, 0.169])\n",
      " list([1, 6, 12, 3, 47, 0.035, 0.064, 0.063, 0.04, 0.048999999999999995, 0.061, 0.051000000000000004, 0.039, 0.059, 0.059, 0.037000000000000005, 0.05, 0.059000000000000004, 0.08299999999999999, 0.176, 0.238, 0.312, 0.169, 0.251])\n",
      " list([1, 6, 12, 3, 47, 0.035, 0.064, 0.063, 0.04, 0.048999999999999995, 0.061, 0.051000000000000004, 0.039, 0.059, 0.059, 0.037000000000000005, 0.05, 0.059000000000000004, 0.08299999999999999, 0.176, 0.238, 0.312, 0.169, 0.251, 0.362])\n",
      " list([1, 6, 12, 3, 47, 0.035, 0.064, 0.063, 0.04, 0.048999999999999995, 0.061, 0.051000000000000004, 0.039, 0.059, 0.059, 0.037000000000000005, 0.05, 0.059000000000000004, 0.08299999999999999, 0.176, 0.238, 0.312, 0.169, 0.251, 0.362, 0.324])\n",
      " list([1, 6, 12, 3, 47, 0.035, 0.064, 0.063, 0.04, 0.048999999999999995, 0.061, 0.051000000000000004, 0.039, 0.059, 0.059, 0.037000000000000005, 0.05, 0.059000000000000004, 0.08299999999999999, 0.176, 0.238, 0.312, 0.169, 0.251, 0.362, 0.324, 0.318])\n",
      " list([1, 6, 12, 3, 47, 0.035, 0.064, 0.063, 0.04, 0.048999999999999995, 0.061, 0.051000000000000004, 0.039, 0.059, 0.059, 0.037000000000000005, 0.05, 0.059000000000000004, 0.08299999999999999, 0.176, 0.238, 0.312, 0.169, 0.251, 0.362, 0.324, 0.318, 0.25])\n",
      " list([1, 6, 12, 3, 47, 0.035, 0.064, 0.063, 0.04, 0.048999999999999995, 0.061, 0.051000000000000004, 0.039, 0.059, 0.059, 0.037000000000000005, 0.05, 0.059000000000000004, 0.08299999999999999, 0.176, 0.238, 0.312, 0.169, 0.251, 0.362, 0.324, 0.318, 0.25, 0.263])\n",
      " list([1, 1, 1, 12, 26, 0.091])\n",
      " list([1, 1, 1, 12, 26, 0.091, 0.08800000000000001])\n",
      " list([1, 1, 1, 12, 26, 0.091, 0.08800000000000001, 0.107])\n",
      " list([1, 1, 1, 12, 26, 0.091, 0.08800000000000001, 0.107, 0.073])\n",
      " list([1, 1, 1, 12, 26, 0.091, 0.08800000000000001, 0.107, 0.073, 0.094])\n",
      " list([1, 1, 1, 12, 26, 0.091, 0.08800000000000001, 0.107, 0.073, 0.094, 0.1])\n",
      " list([1, 1, 1, 12, 26, 0.091, 0.08800000000000001, 0.107, 0.073, 0.094, 0.1, 0.07200000000000001])\n",
      " list([1, 1, 1, 12, 26, 0.091, 0.08800000000000001, 0.107, 0.073, 0.094, 0.1, 0.07200000000000001, 0.09])\n",
      " list([1, 1, 1, 12, 26, 0.091, 0.08800000000000001, 0.107, 0.073, 0.094, 0.1, 0.07200000000000001, 0.09, 0.097])\n",
      " list([1, 1, 1, 12, 26, 0.091, 0.08800000000000001, 0.107, 0.073, 0.094, 0.1, 0.07200000000000001, 0.09, 0.097, 0.073])\n",
      " list([1, 1, 1, 12, 26, 0.091, 0.08800000000000001, 0.107, 0.073, 0.094, 0.1, 0.07200000000000001, 0.09, 0.097, 0.073, 0.085])\n",
      " list([1, 1, 1, 12, 26, 0.091, 0.08800000000000001, 0.107, 0.073, 0.094, 0.1, 0.07200000000000001, 0.09, 0.097, 0.073, 0.085, 0.094])\n",
      " list([1, 1, 1, 12, 26, 0.091, 0.08800000000000001, 0.107, 0.073, 0.094, 0.1, 0.07200000000000001, 0.09, 0.097, 0.073, 0.085, 0.094, 0.08])\n",
      " list([1, 1, 1, 12, 26, 0.091, 0.08800000000000001, 0.107, 0.073, 0.094, 0.1, 0.07200000000000001, 0.09, 0.097, 0.073, 0.085, 0.094, 0.08, 0.076])\n",
      " list([1, 1, 1, 12, 26, 0.091, 0.08800000000000001, 0.107, 0.073, 0.094, 0.1, 0.07200000000000001, 0.09, 0.097, 0.073, 0.085, 0.094, 0.08, 0.076, 0.09300000000000001])\n",
      " list([1, 1, 1, 12, 26, 0.091, 0.08800000000000001, 0.107, 0.073, 0.094, 0.1, 0.07200000000000001, 0.09, 0.097, 0.073, 0.085, 0.094, 0.08, 0.076, 0.09300000000000001, 0.088])\n",
      " list([1, 1, 1, 12, 26, 0.091, 0.08800000000000001, 0.107, 0.073, 0.094, 0.1, 0.07200000000000001, 0.09, 0.097, 0.073, 0.085, 0.094, 0.08, 0.076, 0.09300000000000001, 0.088, 0.068])\n",
      " list([1, 1, 1, 12, 26, 0.091, 0.08800000000000001, 0.107, 0.073, 0.094, 0.1, 0.07200000000000001, 0.09, 0.097, 0.073, 0.085, 0.094, 0.08, 0.076, 0.09300000000000001, 0.088, 0.068, 0.094])\n",
      " list([1, 1, 1, 12, 26, 0.091, 0.08800000000000001, 0.107, 0.073, 0.094, 0.1, 0.07200000000000001, 0.09, 0.097, 0.073, 0.085, 0.094, 0.08, 0.076, 0.09300000000000001, 0.088, 0.068, 0.094, 0.095])\n",
      " list([1, 1, 1, 12, 26, 0.091, 0.08800000000000001, 0.107, 0.073, 0.094, 0.1, 0.07200000000000001, 0.09, 0.097, 0.073, 0.085, 0.094, 0.08, 0.076, 0.09300000000000001, 0.088, 0.068, 0.094, 0.095, 0.25])\n",
      " list([1, 1, 1, 12, 26, 0.091, 0.08800000000000001, 0.107, 0.073, 0.094, 0.1, 0.07200000000000001, 0.09, 0.097, 0.073, 0.085, 0.094, 0.08, 0.076, 0.09300000000000001, 0.088, 0.068, 0.094, 0.095, 0.25, 0.3])\n",
      " list([1, 1, 1, 12, 26, 0.091, 0.08800000000000001, 0.107, 0.073, 0.094, 0.1, 0.07200000000000001, 0.09, 0.097, 0.073, 0.085, 0.094, 0.08, 0.076, 0.09300000000000001, 0.088, 0.068, 0.094, 0.095, 0.25, 0.3, 0.248])\n",
      " list([1, 1, 1, 12, 26, 0.091, 0.08800000000000001, 0.107, 0.073, 0.094, 0.1, 0.07200000000000001, 0.09, 0.097, 0.073, 0.085, 0.094, 0.08, 0.076, 0.09300000000000001, 0.088, 0.068, 0.094, 0.095, 0.25, 0.3, 0.248, 0.243])\n",
      " list([1, 1, 1, 12, 26, 0.091, 0.08800000000000001, 0.107, 0.073, 0.094, 0.1, 0.07200000000000001, 0.09, 0.097, 0.073, 0.085, 0.094, 0.08, 0.076, 0.09300000000000001, 0.088, 0.068, 0.094, 0.095, 0.25, 0.3, 0.248, 0.243, 0.098])\n",
      " list([1, 6, 2, 22, 50, 0.31]) list([1, 6, 2, 22, 50, 0.31, 0.255])\n",
      " list([1, 6, 2, 22, 50, 0.31, 0.255, 0.211])\n",
      " list([1, 6, 2, 22, 50, 0.31, 0.255, 0.211, 0.20700000000000002])\n",
      " list([1, 6, 2, 22, 50, 0.31, 0.255, 0.211, 0.20700000000000002, 0.202])\n",
      " list([1, 6, 2, 22, 50, 0.31, 0.255, 0.211, 0.20700000000000002, 0.202, 0.202])\n",
      " list([1, 6, 2, 22, 50, 0.31, 0.255, 0.211, 0.20700000000000002, 0.202, 0.202, 0.17200000000000001])\n",
      " list([1, 6, 2, 22, 50, 0.31, 0.255, 0.211, 0.20700000000000002, 0.202, 0.202, 0.17200000000000001, 0.193])\n",
      " list([1, 6, 2, 22, 50, 0.31, 0.255, 0.211, 0.20700000000000002, 0.202, 0.202, 0.17200000000000001, 0.193, 0.181])\n",
      " list([1, 6, 2, 22, 50, 0.31, 0.255, 0.211, 0.20700000000000002, 0.202, 0.202, 0.17200000000000001, 0.193, 0.181, 0.176])\n",
      " list([1, 6, 2, 22, 50, 0.31, 0.255, 0.211, 0.20700000000000002, 0.202, 0.202, 0.17200000000000001, 0.193, 0.181, 0.176, 0.187])\n",
      " list([1, 6, 2, 22, 50, 0.31, 0.255, 0.211, 0.20700000000000002, 0.202, 0.202, 0.17200000000000001, 0.193, 0.181, 0.176, 0.187, 0.223])\n",
      " list([1, 6, 2, 22, 50, 0.31, 0.255, 0.211, 0.20700000000000002, 0.202, 0.202, 0.17200000000000001, 0.193, 0.181, 0.176, 0.187, 0.223, 0.322])\n",
      " list([1, 6, 2, 22, 50, 0.31, 0.255, 0.211, 0.20700000000000002, 0.202, 0.202, 0.17200000000000001, 0.193, 0.181, 0.176, 0.187, 0.223, 0.322, 0.28900000000000003])\n",
      " list([1, 6, 2, 22, 50, 0.31, 0.255, 0.211, 0.20700000000000002, 0.202, 0.202, 0.17200000000000001, 0.193, 0.181, 0.176, 0.187, 0.223, 0.322, 0.28900000000000003, 0.219])\n",
      " list([1, 6, 2, 22, 50, 0.31, 0.255, 0.211, 0.20700000000000002, 0.202, 0.202, 0.17200000000000001, 0.193, 0.181, 0.176, 0.187, 0.223, 0.322, 0.28900000000000003, 0.219, 0.187])\n",
      " list([1, 6, 2, 22, 50, 0.31, 0.255, 0.211, 0.20700000000000002, 0.202, 0.202, 0.17200000000000001, 0.193, 0.181, 0.176, 0.187, 0.223, 0.322, 0.28900000000000003, 0.219, 0.187, 0.219])\n",
      " list([1, 6, 2, 22, 50, 0.31, 0.255, 0.211, 0.20700000000000002, 0.202, 0.202, 0.17200000000000001, 0.193, 0.181, 0.176, 0.187, 0.223, 0.322, 0.28900000000000003, 0.219, 0.187, 0.219, 0.22399999999999998])\n",
      " list([1, 6, 2, 22, 50, 0.31, 0.255, 0.211, 0.20700000000000002, 0.202, 0.202, 0.17200000000000001, 0.193, 0.181, 0.176, 0.187, 0.223, 0.322, 0.28900000000000003, 0.219, 0.187, 0.219, 0.22399999999999998, 0.226])\n",
      " list([1, 6, 2, 22, 50, 0.31, 0.255, 0.211, 0.20700000000000002, 0.202, 0.202, 0.17200000000000001, 0.193, 0.181, 0.176, 0.187, 0.223, 0.322, 0.28900000000000003, 0.219, 0.187, 0.219, 0.22399999999999998, 0.226, 0.22])\n",
      " list([1, 6, 2, 22, 50, 0.31, 0.255, 0.211, 0.20700000000000002, 0.202, 0.202, 0.17200000000000001, 0.193, 0.181, 0.176, 0.187, 0.223, 0.322, 0.28900000000000003, 0.219, 0.187, 0.219, 0.22399999999999998, 0.226, 0.22, 0.216])\n",
      " list([1, 6, 2, 22, 50, 0.31, 0.255, 0.211, 0.20700000000000002, 0.202, 0.202, 0.17200000000000001, 0.193, 0.181, 0.176, 0.187, 0.223, 0.322, 0.28900000000000003, 0.219, 0.187, 0.219, 0.22399999999999998, 0.226, 0.22, 0.216, 0.215])\n",
      " list([1, 6, 2, 22, 50, 0.31, 0.255, 0.211, 0.20700000000000002, 0.202, 0.202, 0.17200000000000001, 0.193, 0.181, 0.176, 0.187, 0.223, 0.322, 0.28900000000000003, 0.219, 0.187, 0.219, 0.22399999999999998, 0.226, 0.22, 0.216, 0.215, 0.215])\n",
      " list([1, 6, 2, 22, 50, 0.31, 0.255, 0.211, 0.20700000000000002, 0.202, 0.202, 0.17200000000000001, 0.193, 0.181, 0.176, 0.187, 0.223, 0.322, 0.28900000000000003, 0.219, 0.187, 0.219, 0.22399999999999998, 0.226, 0.22, 0.216, 0.215, 0.215, 0.215])\n",
      " list([1, 6, 1, 7, 32, 0.174]) list([1, 6, 1, 7, 32, 0.174, 0.089])\n",
      " list([1, 6, 1, 7, 32, 0.174, 0.089, 0.08299999999999999])\n",
      " list([1, 6, 1, 7, 32, 0.174, 0.089, 0.08299999999999999, 0.071])\n",
      " list([1, 6, 1, 7, 32, 0.174, 0.089, 0.08299999999999999, 0.071, 0.097])\n",
      " list([1, 6, 1, 7, 32, 0.174, 0.089, 0.08299999999999999, 0.071, 0.097, 0.101])\n",
      " list([1, 6, 1, 7, 32, 0.174, 0.089, 0.08299999999999999, 0.071, 0.097, 0.101, 0.076])\n",
      " list([1, 6, 1, 7, 32, 0.174, 0.089, 0.08299999999999999, 0.071, 0.097, 0.101, 0.076, 0.11200000000000002])\n",
      " list([1, 6, 1, 7, 32, 0.174, 0.089, 0.08299999999999999, 0.071, 0.097, 0.101, 0.076, 0.11200000000000002, 0.26])\n",
      " list([1, 6, 1, 7, 32, 0.174, 0.089, 0.08299999999999999, 0.071, 0.097, 0.101, 0.076, 0.11200000000000002, 0.26, 0.346])\n",
      " list([1, 6, 1, 7, 32, 0.174, 0.089, 0.08299999999999999, 0.071, 0.097, 0.101, 0.076, 0.11200000000000002, 0.26, 0.346, 0.226])\n",
      " list([1, 6, 1, 7, 32, 0.174, 0.089, 0.08299999999999999, 0.071, 0.097, 0.101, 0.076, 0.11200000000000002, 0.26, 0.346, 0.226, 0.154])\n",
      " list([1, 6, 1, 7, 32, 0.174, 0.089, 0.08299999999999999, 0.071, 0.097, 0.101, 0.076, 0.11200000000000002, 0.26, 0.346, 0.226, 0.154, 0.145])\n",
      " list([1, 6, 1, 7, 32, 0.174, 0.089, 0.08299999999999999, 0.071, 0.097, 0.101, 0.076, 0.11200000000000002, 0.26, 0.346, 0.226, 0.154, 0.145, 0.20099999999999998])\n",
      " list([1, 6, 1, 7, 32, 0.174, 0.089, 0.08299999999999999, 0.071, 0.097, 0.101, 0.076, 0.11200000000000002, 0.26, 0.346, 0.226, 0.154, 0.145, 0.20099999999999998, 0.275])\n",
      " list([1, 6, 1, 7, 32, 0.174, 0.089, 0.08299999999999999, 0.071, 0.097, 0.101, 0.076, 0.11200000000000002, 0.26, 0.346, 0.226, 0.154, 0.145, 0.20099999999999998, 0.275, 0.254])\n",
      " list([1, 6, 1, 7, 32, 0.174, 0.089, 0.08299999999999999, 0.071, 0.097, 0.101, 0.076, 0.11200000000000002, 0.26, 0.346, 0.226, 0.154, 0.145, 0.20099999999999998, 0.275, 0.254, 0.243])\n",
      " list([1, 6, 1, 7, 32, 0.174, 0.089, 0.08299999999999999, 0.071, 0.097, 0.101, 0.076, 0.11200000000000002, 0.26, 0.346, 0.226, 0.154, 0.145, 0.20099999999999998, 0.275, 0.254, 0.243, 0.224])\n",
      " list([1, 6, 1, 7, 32, 0.174, 0.089, 0.08299999999999999, 0.071, 0.097, 0.101, 0.076, 0.11200000000000002, 0.26, 0.346, 0.226, 0.154, 0.145, 0.20099999999999998, 0.275, 0.254, 0.243, 0.224, 0.081])\n",
      " list([1, 6, 1, 7, 32, 0.174, 0.089, 0.08299999999999999, 0.071, 0.097, 0.101, 0.076, 0.11200000000000002, 0.26, 0.346, 0.226, 0.154, 0.145, 0.20099999999999998, 0.275, 0.254, 0.243, 0.224, 0.081, 0.093])\n",
      " list([1, 6, 1, 7, 32, 0.174, 0.089, 0.08299999999999999, 0.071, 0.097, 0.101, 0.076, 0.11200000000000002, 0.26, 0.346, 0.226, 0.154, 0.145, 0.20099999999999998, 0.275, 0.254, 0.243, 0.224, 0.081, 0.093, 0.104])\n",
      " list([1, 6, 1, 7, 32, 0.174, 0.089, 0.08299999999999999, 0.071, 0.097, 0.101, 0.076, 0.11200000000000002, 0.26, 0.346, 0.226, 0.154, 0.145, 0.20099999999999998, 0.275, 0.254, 0.243, 0.224, 0.081, 0.093, 0.104, 0.394])\n",
      " list([1, 6, 1, 7, 32, 0.174, 0.089, 0.08299999999999999, 0.071, 0.097, 0.101, 0.076, 0.11200000000000002, 0.26, 0.346, 0.226, 0.154, 0.145, 0.20099999999999998, 0.275, 0.254, 0.243, 0.224, 0.081, 0.093, 0.104, 0.394, 0.46299999999999997])\n",
      " list([1, 6, 1, 7, 32, 0.174, 0.089, 0.08299999999999999, 0.071, 0.097, 0.101, 0.076, 0.11200000000000002, 0.26, 0.346, 0.226, 0.154, 0.145, 0.20099999999999998, 0.275, 0.254, 0.243, 0.224, 0.081, 0.093, 0.104, 0.394, 0.46299999999999997, 0.336])\n",
      " list([1, 2, 1, 7, 37, 0.048]) list([1, 2, 1, 7, 37, 0.048, 0.075])\n",
      " list([1, 2, 1, 7, 37, 0.048, 0.075, 0.078])\n",
      " list([1, 2, 1, 7, 37, 0.048, 0.075, 0.078, 0.049])\n",
      " list([1, 2, 1, 7, 37, 0.048, 0.075, 0.078, 0.049, 0.066])\n",
      " list([1, 2, 1, 7, 37, 0.048, 0.075, 0.078, 0.049, 0.066, 0.073])\n",
      " list([1, 2, 1, 7, 37, 0.048, 0.075, 0.078, 0.049, 0.066, 0.073, 0.056])\n",
      " list([1, 2, 1, 7, 37, 0.048, 0.075, 0.078, 0.049, 0.066, 0.073, 0.056, 0.047])\n",
      " list([1, 2, 1, 7, 37, 0.048, 0.075, 0.078, 0.049, 0.066, 0.073, 0.056, 0.047, 0.057])\n",
      " list([1, 2, 1, 7, 37, 0.048, 0.075, 0.078, 0.049, 0.066, 0.073, 0.056, 0.047, 0.057, 0.048])\n",
      " list([1, 2, 1, 7, 37, 0.048, 0.075, 0.078, 0.049, 0.066, 0.073, 0.056, 0.047, 0.057, 0.048, 0.038])\n",
      " list([1, 2, 1, 7, 37, 0.048, 0.075, 0.078, 0.049, 0.066, 0.073, 0.056, 0.047, 0.057, 0.048, 0.038, 0.057])\n",
      " list([1, 2, 1, 7, 37, 0.048, 0.075, 0.078, 0.049, 0.066, 0.073, 0.056, 0.047, 0.057, 0.048, 0.038, 0.057, 0.052000000000000005])\n",
      " list([1, 2, 1, 7, 37, 0.048, 0.075, 0.078, 0.049, 0.066, 0.073, 0.056, 0.047, 0.057, 0.048, 0.038, 0.057, 0.052000000000000005, 0.032])\n",
      " list([1, 2, 1, 7, 37, 0.048, 0.075, 0.078, 0.049, 0.066, 0.073, 0.056, 0.047, 0.057, 0.048, 0.038, 0.057, 0.052000000000000005, 0.032, 0.057])\n",
      " list([1, 2, 1, 7, 37, 0.048, 0.075, 0.078, 0.049, 0.066, 0.073, 0.056, 0.047, 0.057, 0.048, 0.038, 0.057, 0.052000000000000005, 0.032, 0.057, 0.054])\n",
      " list([1, 2, 1, 7, 37, 0.048, 0.075, 0.078, 0.049, 0.066, 0.073, 0.056, 0.047, 0.057, 0.048, 0.038, 0.057, 0.052000000000000005, 0.032, 0.057, 0.054, 0.031])\n",
      " list([1, 2, 1, 7, 37, 0.048, 0.075, 0.078, 0.049, 0.066, 0.073, 0.056, 0.047, 0.057, 0.048, 0.038, 0.057, 0.052000000000000005, 0.032, 0.057, 0.054, 0.031, 0.142])\n",
      " list([1, 2, 1, 7, 37, 0.048, 0.075, 0.078, 0.049, 0.066, 0.073, 0.056, 0.047, 0.057, 0.048, 0.038, 0.057, 0.052000000000000005, 0.032, 0.057, 0.054, 0.031, 0.142, 0.242])\n",
      " list([1, 2, 1, 7, 37, 0.048, 0.075, 0.078, 0.049, 0.066, 0.073, 0.056, 0.047, 0.057, 0.048, 0.038, 0.057, 0.052000000000000005, 0.032, 0.057, 0.054, 0.031, 0.142, 0.242, 0.26])\n",
      " list([1, 2, 1, 7, 37, 0.048, 0.075, 0.078, 0.049, 0.066, 0.073, 0.056, 0.047, 0.057, 0.048, 0.038, 0.057, 0.052000000000000005, 0.032, 0.057, 0.054, 0.031, 0.142, 0.242, 0.26, 0.26])\n",
      " list([1, 2, 1, 7, 37, 0.048, 0.075, 0.078, 0.049, 0.066, 0.073, 0.056, 0.047, 0.057, 0.048, 0.038, 0.057, 0.052000000000000005, 0.032, 0.057, 0.054, 0.031, 0.142, 0.242, 0.26, 0.26, 0.267])\n",
      " list([1, 2, 1, 7, 37, 0.048, 0.075, 0.078, 0.049, 0.066, 0.073, 0.056, 0.047, 0.057, 0.048, 0.038, 0.057, 0.052000000000000005, 0.032, 0.057, 0.054, 0.031, 0.142, 0.242, 0.26, 0.26, 0.267, 0.235])\n",
      " list([1, 2, 1, 7, 37, 0.048, 0.075, 0.078, 0.049, 0.066, 0.073, 0.056, 0.047, 0.057, 0.048, 0.038, 0.057, 0.052000000000000005, 0.032, 0.057, 0.054, 0.031, 0.142, 0.242, 0.26, 0.26, 0.267, 0.235, 0.22899999999999998])\n",
      " list([1, 3, 3, 17, 57, 0.257]) list([1, 3, 3, 17, 57, 0.257, 0.181])\n",
      " list([1, 3, 3, 17, 57, 0.257, 0.181, 0.174])\n",
      " list([1, 3, 3, 17, 57, 0.257, 0.181, 0.174, 0.17099999999999999])\n",
      " list([1, 3, 3, 17, 57, 0.257, 0.181, 0.174, 0.17099999999999999, 0.17400000000000002])\n",
      " list([1, 3, 3, 17, 57, 0.257, 0.181, 0.174, 0.17099999999999999, 0.17400000000000002, 0.171])\n",
      " list([1, 3, 3, 17, 57, 0.257, 0.181, 0.174, 0.17099999999999999, 0.17400000000000002, 0.171, 0.17200000000000001])\n",
      " list([1, 3, 3, 17, 57, 0.257, 0.181, 0.174, 0.17099999999999999, 0.17400000000000002, 0.171, 0.17200000000000001, 0.21700000000000003])\n",
      " list([1, 3, 3, 17, 57, 0.257, 0.181, 0.174, 0.17099999999999999, 0.17400000000000002, 0.171, 0.17200000000000001, 0.21700000000000003, 0.188])\n",
      " list([1, 3, 3, 17, 57, 0.257, 0.181, 0.174, 0.17099999999999999, 0.17400000000000002, 0.171, 0.17200000000000001, 0.21700000000000003, 0.188, 0.189])\n",
      " list([1, 3, 3, 17, 57, 0.257, 0.181, 0.174, 0.17099999999999999, 0.17400000000000002, 0.171, 0.17200000000000001, 0.21700000000000003, 0.188, 0.189, 0.21499999999999997])\n",
      " list([1, 3, 3, 17, 57, 0.257, 0.181, 0.174, 0.17099999999999999, 0.17400000000000002, 0.171, 0.17200000000000001, 0.21700000000000003, 0.188, 0.189, 0.21499999999999997, 0.223])\n",
      " list([1, 3, 3, 17, 57, 0.257, 0.181, 0.174, 0.17099999999999999, 0.17400000000000002, 0.171, 0.17200000000000001, 0.21700000000000003, 0.188, 0.189, 0.21499999999999997, 0.223, 0.218])\n",
      " list([1, 3, 3, 17, 57, 0.257, 0.181, 0.174, 0.17099999999999999, 0.17400000000000002, 0.171, 0.17200000000000001, 0.21700000000000003, 0.188, 0.189, 0.21499999999999997, 0.223, 0.218, 0.216])\n",
      " list([1, 3, 3, 17, 57, 0.257, 0.181, 0.174, 0.17099999999999999, 0.17400000000000002, 0.171, 0.17200000000000001, 0.21700000000000003, 0.188, 0.189, 0.21499999999999997, 0.223, 0.218, 0.216, 0.217])\n",
      " list([1, 3, 3, 17, 57, 0.257, 0.181, 0.174, 0.17099999999999999, 0.17400000000000002, 0.171, 0.17200000000000001, 0.21700000000000003, 0.188, 0.189, 0.21499999999999997, 0.223, 0.218, 0.216, 0.217, 0.188])\n",
      " list([1, 3, 3, 17, 57, 0.257, 0.181, 0.174, 0.17099999999999999, 0.17400000000000002, 0.171, 0.17200000000000001, 0.21700000000000003, 0.188, 0.189, 0.21499999999999997, 0.223, 0.218, 0.216, 0.217, 0.188, 0.20700000000000002])\n",
      " list([1, 3, 3, 17, 57, 0.257, 0.181, 0.174, 0.17099999999999999, 0.17400000000000002, 0.171, 0.17200000000000001, 0.21700000000000003, 0.188, 0.189, 0.21499999999999997, 0.223, 0.218, 0.216, 0.217, 0.188, 0.20700000000000002, 0.19399999999999998])\n",
      " list([1, 3, 3, 17, 57, 0.257, 0.181, 0.174, 0.17099999999999999, 0.17400000000000002, 0.171, 0.17200000000000001, 0.21700000000000003, 0.188, 0.189, 0.21499999999999997, 0.223, 0.218, 0.216, 0.217, 0.188, 0.20700000000000002, 0.19399999999999998, 0.187])\n",
      " list([1, 3, 3, 17, 57, 0.257, 0.181, 0.174, 0.17099999999999999, 0.17400000000000002, 0.171, 0.17200000000000001, 0.21700000000000003, 0.188, 0.189, 0.21499999999999997, 0.223, 0.218, 0.216, 0.217, 0.188, 0.20700000000000002, 0.19399999999999998, 0.187, 0.253])\n",
      " list([1, 3, 3, 17, 57, 0.257, 0.181, 0.174, 0.17099999999999999, 0.17400000000000002, 0.171, 0.17200000000000001, 0.21700000000000003, 0.188, 0.189, 0.21499999999999997, 0.223, 0.218, 0.216, 0.217, 0.188, 0.20700000000000002, 0.19399999999999998, 0.187, 0.253, 0.336])\n",
      " list([1, 3, 3, 17, 57, 0.257, 0.181, 0.174, 0.17099999999999999, 0.17400000000000002, 0.171, 0.17200000000000001, 0.21700000000000003, 0.188, 0.189, 0.21499999999999997, 0.223, 0.218, 0.216, 0.217, 0.188, 0.20700000000000002, 0.19399999999999998, 0.187, 0.253, 0.336, 0.413])\n",
      " list([1, 3, 3, 17, 57, 0.257, 0.181, 0.174, 0.17099999999999999, 0.17400000000000002, 0.171, 0.17200000000000001, 0.21700000000000003, 0.188, 0.189, 0.21499999999999997, 0.223, 0.218, 0.216, 0.217, 0.188, 0.20700000000000002, 0.19399999999999998, 0.187, 0.253, 0.336, 0.413, 0.399])\n",
      " list([1, 3, 3, 17, 57, 0.257, 0.181, 0.174, 0.17099999999999999, 0.17400000000000002, 0.171, 0.17200000000000001, 0.21700000000000003, 0.188, 0.189, 0.21499999999999997, 0.223, 0.218, 0.216, 0.217, 0.188, 0.20700000000000002, 0.19399999999999998, 0.187, 0.253, 0.336, 0.413, 0.399, 0.178])\n",
      " list([1, 4, 9, 18, 47, 0.176])\n",
      " list([1, 4, 9, 18, 47, 0.176, 0.17500000000000002])\n",
      " list([1, 4, 9, 18, 47, 0.176, 0.17500000000000002, 0.211])\n",
      " list([1, 4, 9, 18, 47, 0.176, 0.17500000000000002, 0.211, 0.211])\n",
      " list([1, 4, 9, 18, 47, 0.176, 0.17500000000000002, 0.211, 0.211, 0.20400000000000001])\n",
      " list([1, 4, 9, 18, 47, 0.176, 0.17500000000000002, 0.211, 0.211, 0.20400000000000001, 0.202])\n",
      " list([1, 4, 9, 18, 47, 0.176, 0.17500000000000002, 0.211, 0.211, 0.20400000000000001, 0.202, 0.176])\n",
      " list([1, 4, 9, 18, 47, 0.176, 0.17500000000000002, 0.211, 0.211, 0.20400000000000001, 0.202, 0.176, 0.241])\n",
      " list([1, 4, 9, 18, 47, 0.176, 0.17500000000000002, 0.211, 0.211, 0.20400000000000001, 0.202, 0.176, 0.241, 0.17500000000000002])\n",
      " list([1, 4, 9, 18, 47, 0.176, 0.17500000000000002, 0.211, 0.211, 0.20400000000000001, 0.202, 0.176, 0.241, 0.17500000000000002, 0.17400000000000002])\n",
      " list([1, 4, 9, 18, 47, 0.176, 0.17500000000000002, 0.211, 0.211, 0.20400000000000001, 0.202, 0.176, 0.241, 0.17500000000000002, 0.17400000000000002, 0.17800000000000002])\n",
      " list([1, 4, 9, 18, 47, 0.176, 0.17500000000000002, 0.211, 0.211, 0.20400000000000001, 0.202, 0.176, 0.241, 0.17500000000000002, 0.17400000000000002, 0.17800000000000002, 0.18400000000000002])\n",
      " list([1, 4, 9, 18, 47, 0.176, 0.17500000000000002, 0.211, 0.211, 0.20400000000000001, 0.202, 0.176, 0.241, 0.17500000000000002, 0.17400000000000002, 0.17800000000000002, 0.18400000000000002, 0.185])\n",
      " list([1, 4, 9, 18, 47, 0.176, 0.17500000000000002, 0.211, 0.211, 0.20400000000000001, 0.202, 0.176, 0.241, 0.17500000000000002, 0.17400000000000002, 0.17800000000000002, 0.18400000000000002, 0.185, 0.175])\n",
      " list([1, 4, 9, 18, 47, 0.176, 0.17500000000000002, 0.211, 0.211, 0.20400000000000001, 0.202, 0.176, 0.241, 0.17500000000000002, 0.17400000000000002, 0.17800000000000002, 0.18400000000000002, 0.185, 0.175, 0.177])\n",
      " list([1, 4, 9, 18, 47, 0.176, 0.17500000000000002, 0.211, 0.211, 0.20400000000000001, 0.202, 0.176, 0.241, 0.17500000000000002, 0.17400000000000002, 0.17800000000000002, 0.18400000000000002, 0.185, 0.175, 0.177, 0.175])\n",
      " list([1, 4, 9, 18, 47, 0.176, 0.17500000000000002, 0.211, 0.211, 0.20400000000000001, 0.202, 0.176, 0.241, 0.17500000000000002, 0.17400000000000002, 0.17800000000000002, 0.18400000000000002, 0.185, 0.175, 0.177, 0.175, 0.175])\n",
      " list([1, 4, 9, 18, 47, 0.176, 0.17500000000000002, 0.211, 0.211, 0.20400000000000001, 0.202, 0.176, 0.241, 0.17500000000000002, 0.17400000000000002, 0.17800000000000002, 0.18400000000000002, 0.185, 0.175, 0.177, 0.175, 0.175, 0.176])\n",
      " list([1, 4, 9, 18, 47, 0.176, 0.17500000000000002, 0.211, 0.211, 0.20400000000000001, 0.202, 0.176, 0.241, 0.17500000000000002, 0.17400000000000002, 0.17800000000000002, 0.18400000000000002, 0.185, 0.175, 0.177, 0.175, 0.175, 0.176, 0.215])\n",
      " list([1, 4, 9, 18, 47, 0.176, 0.17500000000000002, 0.211, 0.211, 0.20400000000000001, 0.202, 0.176, 0.241, 0.17500000000000002, 0.17400000000000002, 0.17800000000000002, 0.18400000000000002, 0.185, 0.175, 0.177, 0.175, 0.175, 0.176, 0.215, 0.20099999999999998])\n",
      " list([1, 4, 9, 18, 47, 0.176, 0.17500000000000002, 0.211, 0.211, 0.20400000000000001, 0.202, 0.176, 0.241, 0.17500000000000002, 0.17400000000000002, 0.17800000000000002, 0.18400000000000002, 0.185, 0.175, 0.177, 0.175, 0.175, 0.176, 0.215, 0.20099999999999998, 0.206])\n",
      " list([1, 4, 9, 18, 47, 0.176, 0.17500000000000002, 0.211, 0.211, 0.20400000000000001, 0.202, 0.176, 0.241, 0.17500000000000002, 0.17400000000000002, 0.17800000000000002, 0.18400000000000002, 0.185, 0.175, 0.177, 0.175, 0.175, 0.176, 0.215, 0.20099999999999998, 0.206, 0.2])\n",
      " list([1, 4, 9, 18, 47, 0.176, 0.17500000000000002, 0.211, 0.211, 0.20400000000000001, 0.202, 0.176, 0.241, 0.17500000000000002, 0.17400000000000002, 0.17800000000000002, 0.18400000000000002, 0.185, 0.175, 0.177, 0.175, 0.175, 0.176, 0.215, 0.20099999999999998, 0.206, 0.2, 0.197])\n",
      " list([1, 4, 9, 18, 47, 0.176, 0.17500000000000002, 0.211, 0.211, 0.20400000000000001, 0.202, 0.176, 0.241, 0.17500000000000002, 0.17400000000000002, 0.17800000000000002, 0.18400000000000002, 0.185, 0.175, 0.177, 0.175, 0.175, 0.176, 0.215, 0.20099999999999998, 0.206, 0.2, 0.197, 0.197])\n",
      " list([1, 3, 3, 15, 90, 0.27499999999999997])\n",
      " list([1, 3, 3, 15, 90, 0.27499999999999997, 0.201])\n",
      " list([1, 3, 3, 15, 90, 0.27499999999999997, 0.201, 0.17600000000000002])\n",
      " list([1, 3, 3, 15, 90, 0.27499999999999997, 0.201, 0.17600000000000002, 0.21])\n",
      " list([1, 3, 3, 15, 90, 0.27499999999999997, 0.201, 0.17600000000000002, 0.21, 0.19899999999999998])\n",
      " list([1, 3, 3, 15, 90, 0.27499999999999997, 0.201, 0.17600000000000002, 0.21, 0.19899999999999998, 0.202])\n",
      " list([1, 3, 3, 15, 90, 0.27499999999999997, 0.201, 0.17600000000000002, 0.21, 0.19899999999999998, 0.202, 0.199])\n",
      " list([1, 3, 3, 15, 90, 0.27499999999999997, 0.201, 0.17600000000000002, 0.21, 0.19899999999999998, 0.202, 0.199, 0.252])\n",
      " list([1, 3, 3, 15, 90, 0.27499999999999997, 0.201, 0.17600000000000002, 0.21, 0.19899999999999998, 0.202, 0.199, 0.252, 0.21300000000000002])\n",
      " list([1, 3, 3, 15, 90, 0.27499999999999997, 0.201, 0.17600000000000002, 0.21, 0.19899999999999998, 0.202, 0.199, 0.252, 0.21300000000000002, 0.173])\n",
      " list([1, 3, 3, 15, 90, 0.27499999999999997, 0.201, 0.17600000000000002, 0.21, 0.19899999999999998, 0.202, 0.199, 0.252, 0.21300000000000002, 0.173, 0.18600000000000003])\n",
      " list([1, 3, 3, 15, 90, 0.27499999999999997, 0.201, 0.17600000000000002, 0.21, 0.19899999999999998, 0.202, 0.199, 0.252, 0.21300000000000002, 0.173, 0.18600000000000003, 0.188])\n",
      " list([1, 3, 3, 15, 90, 0.27499999999999997, 0.201, 0.17600000000000002, 0.21, 0.19899999999999998, 0.202, 0.199, 0.252, 0.21300000000000002, 0.173, 0.18600000000000003, 0.188, 0.17099999999999999])\n",
      " list([1, 3, 3, 15, 90, 0.27499999999999997, 0.201, 0.17600000000000002, 0.21, 0.19899999999999998, 0.202, 0.199, 0.252, 0.21300000000000002, 0.173, 0.18600000000000003, 0.188, 0.17099999999999999, 0.191])\n",
      " list([1, 3, 3, 15, 90, 0.27499999999999997, 0.201, 0.17600000000000002, 0.21, 0.19899999999999998, 0.202, 0.199, 0.252, 0.21300000000000002, 0.173, 0.18600000000000003, 0.188, 0.17099999999999999, 0.191, 0.175])\n",
      " list([1, 3, 3, 15, 90, 0.27499999999999997, 0.201, 0.17600000000000002, 0.21, 0.19899999999999998, 0.202, 0.199, 0.252, 0.21300000000000002, 0.173, 0.18600000000000003, 0.188, 0.17099999999999999, 0.191, 0.175, 0.168])\n",
      " list([1, 3, 3, 15, 90, 0.27499999999999997, 0.201, 0.17600000000000002, 0.21, 0.19899999999999998, 0.202, 0.199, 0.252, 0.21300000000000002, 0.173, 0.18600000000000003, 0.188, 0.17099999999999999, 0.191, 0.175, 0.168, 0.196])\n",
      " list([1, 3, 3, 15, 90, 0.27499999999999997, 0.201, 0.17600000000000002, 0.21, 0.19899999999999998, 0.202, 0.199, 0.252, 0.21300000000000002, 0.173, 0.18600000000000003, 0.188, 0.17099999999999999, 0.191, 0.175, 0.168, 0.196, 0.177])\n",
      " list([1, 3, 3, 15, 90, 0.27499999999999997, 0.201, 0.17600000000000002, 0.21, 0.19899999999999998, 0.202, 0.199, 0.252, 0.21300000000000002, 0.173, 0.18600000000000003, 0.188, 0.17099999999999999, 0.191, 0.175, 0.168, 0.196, 0.177, 0.218])\n",
      " list([1, 3, 3, 15, 90, 0.27499999999999997, 0.201, 0.17600000000000002, 0.21, 0.19899999999999998, 0.202, 0.199, 0.252, 0.21300000000000002, 0.173, 0.18600000000000003, 0.188, 0.17099999999999999, 0.191, 0.175, 0.168, 0.196, 0.177, 0.218, 0.19999999999999998])\n",
      " list([1, 3, 3, 15, 90, 0.27499999999999997, 0.201, 0.17600000000000002, 0.21, 0.19899999999999998, 0.202, 0.199, 0.252, 0.21300000000000002, 0.173, 0.18600000000000003, 0.188, 0.17099999999999999, 0.191, 0.175, 0.168, 0.196, 0.177, 0.218, 0.19999999999999998, 0.206])\n",
      " list([1, 3, 3, 15, 90, 0.27499999999999997, 0.201, 0.17600000000000002, 0.21, 0.19899999999999998, 0.202, 0.199, 0.252, 0.21300000000000002, 0.173, 0.18600000000000003, 0.188, 0.17099999999999999, 0.191, 0.175, 0.168, 0.196, 0.177, 0.218, 0.19999999999999998, 0.206, 0.202])\n",
      " list([1, 3, 3, 15, 90, 0.27499999999999997, 0.201, 0.17600000000000002, 0.21, 0.19899999999999998, 0.202, 0.199, 0.252, 0.21300000000000002, 0.173, 0.18600000000000003, 0.188, 0.17099999999999999, 0.191, 0.175, 0.168, 0.196, 0.177, 0.218, 0.19999999999999998, 0.206, 0.202, 0.201])\n",
      " list([1, 3, 3, 15, 90, 0.27499999999999997, 0.201, 0.17600000000000002, 0.21, 0.19899999999999998, 0.202, 0.199, 0.252, 0.21300000000000002, 0.173, 0.18600000000000003, 0.188, 0.17099999999999999, 0.191, 0.175, 0.168, 0.196, 0.177, 0.218, 0.19999999999999998, 0.206, 0.202, 0.201, 0.196])]\n",
      "\n",
      "Tranining Sample Size : 336\n",
      "Tranining Sample MAX_LEN : 29\n",
      "\n",
      "Final Samples\n",
      "[[ 0.     0.     0.    ... 20.    73.     0.341]\n",
      " [ 0.     0.     0.    ... 73.     0.341  0.337]\n",
      " [ 0.     0.     0.    ...  0.341  0.337  0.324]\n",
      " ...\n",
      " [ 0.     0.     1.    ...  0.2    0.206  0.202]\n",
      " [ 0.     1.     3.    ...  0.206  0.202  0.201]\n",
      " [ 1.     3.     3.    ...  0.202  0.201  0.196]]\n",
      "Samples Before Padding Process\n",
      "[list([1, 4, 3, 11, 62, 0.18300000000000002])\n",
      " list([1, 4, 3, 11, 62, 0.18300000000000002, 0.235])\n",
      " list([1, 4, 3, 11, 62, 0.18300000000000002, 0.235, 0.16699999999999998])\n",
      " ...\n",
      " list([1, 2, 6, 16, 53, 0.045, 0.044, 0.059, 0.058, 0.033, 0.054, 0.059000000000000004, 0.049, 0.04, 0.057999999999999996, 0.056, 0.03, 0.057999999999999996, 0.06, 0.038, 0.048, 0.062, 0.051000000000000004, 0.038, 0.06099999999999999, 0.059000000000000004, 0.03])\n",
      " list([1, 2, 6, 16, 53, 0.045, 0.044, 0.059, 0.058, 0.033, 0.054, 0.059000000000000004, 0.049, 0.04, 0.057999999999999996, 0.056, 0.03, 0.057999999999999996, 0.06, 0.038, 0.048, 0.062, 0.051000000000000004, 0.038, 0.06099999999999999, 0.059000000000000004, 0.03, 0.055999999999999994])\n",
      " list([1, 2, 6, 16, 53, 0.045, 0.044, 0.059, 0.058, 0.033, 0.054, 0.059000000000000004, 0.049, 0.04, 0.057999999999999996, 0.056, 0.03, 0.057999999999999996, 0.06, 0.038, 0.048, 0.062, 0.051000000000000004, 0.038, 0.06099999999999999, 0.059000000000000004, 0.03, 0.055999999999999994, 0.057999999999999996])]\n",
      "\n",
      "Tranining Sample Size : 1872\n",
      "Tranining Sample MAX_LEN : 29\n",
      "\n",
      "Final Samples\n",
      "[[0.00e+00 0.00e+00 0.00e+00 ... 1.10e+01 6.20e+01 1.83e-01]\n",
      " [0.00e+00 0.00e+00 0.00e+00 ... 6.20e+01 1.83e-01 2.35e-01]\n",
      " [0.00e+00 0.00e+00 0.00e+00 ... 1.83e-01 2.35e-01 1.67e-01]\n",
      " ...\n",
      " [0.00e+00 0.00e+00 1.00e+00 ... 6.10e-02 5.90e-02 3.00e-02]\n",
      " [0.00e+00 1.00e+00 2.00e+00 ... 5.90e-02 3.00e-02 5.60e-02]\n",
      " [1.00e+00 2.00e+00 6.00e+00 ... 3.00e-02 5.60e-02 5.80e-02]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-495-f7267c0eac4d>:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  print(np.array(samples))\n"
     ]
    }
   ],
   "source": [
    "# Config Sample Datas - Padding\n",
    "# Data Preprocessing\n",
    "def get_samples(datas):\n",
    "    samples = list()\n",
    "    for col in datas:\n",
    "        timeslot = datas[col].values.tolist()\n",
    "        weather = wt_datas[wt_datas['date'] == col][sample_weather_col].values.tolist()[0]\n",
    "        for time in range(1,25):\n",
    "            samples.append(weather + timeslot[:time])\n",
    "\n",
    "    print(\"Samples Before Padding Process\")\n",
    "    print(np.array(samples))\n",
    "    print(\"\\nTranining Sample Size : {}\".format(len(samples)))\n",
    "    \n",
    "    return samples\n",
    "\n",
    "def get_padding_samples(samples):    \n",
    "    # Padding\n",
    "    pad_samples = list()\n",
    "    SAMPLE_MAX_LEN = max([len(s) for s in samples])\n",
    "    print(\"Tranining Sample MAX_LEN : {}\".format(SAMPLE_MAX_LEN))\n",
    "    for sample in samples:\n",
    "        err = SAMPLE_MAX_LEN - len(sample)\n",
    "        if err == 0:\n",
    "            pad_samples.append(sample)\n",
    "        else:\n",
    "            pad_data = [0 for i in range(0, err)]\n",
    "            pad_samples.append(pad_data + sample)\n",
    "    print(\"\\nFinal Samples\")\n",
    "    print(np.array(pad_samples))\n",
    "    \n",
    "    return pad_samples\n",
    "    \n",
    "test_samples = get_samples(test_merge_datas)\n",
    "test_samples = get_padding_samples(test_samples)\n",
    "\n",
    "training_samples = get_samples(merge_datas)\n",
    "training_samples = get_padding_samples(training_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "f3b04e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data For Training\n",
      "[[0.00e+00 0.00e+00 0.00e+00 ... 3.00e+00 1.10e+01 6.20e+01]\n",
      " [0.00e+00 0.00e+00 0.00e+00 ... 1.10e+01 6.20e+01 1.83e-01]\n",
      " [0.00e+00 0.00e+00 0.00e+00 ... 6.20e+01 1.83e-01 2.35e-01]\n",
      " ...\n",
      " [0.00e+00 0.00e+00 1.00e+00 ... 3.80e-02 6.10e-02 5.90e-02]\n",
      " [0.00e+00 1.00e+00 2.00e+00 ... 6.10e-02 5.90e-02 3.00e-02]\n",
      " [1.00e+00 2.00e+00 6.00e+00 ... 5.90e-02 3.00e-02 5.60e-02]]\n",
      "\n",
      "Output Data For Training\n",
      "[0.183 0.235 0.167 ... 0.03  0.056 0.058]\n",
      "Input Data For Test\n",
      "[[ 0.     0.     0.    ...  2.    20.    73.   ]\n",
      " [ 0.     0.     0.    ... 20.    73.     0.341]\n",
      " [ 0.     0.     0.    ... 73.     0.341  0.337]\n",
      " ...\n",
      " [ 0.     0.     1.    ...  0.218  0.2    0.206]\n",
      " [ 0.     1.     3.    ...  0.2    0.206  0.202]\n",
      " [ 1.     3.     3.    ...  0.206  0.202  0.201]]\n",
      "\n",
      "Output Data For Test\n",
      "[0.341 0.337 0.324 0.319 0.235 0.169 0.2   0.171 0.17  0.172 0.199 0.169\n",
      " 0.17  0.215 0.212 0.257 0.203 0.198 0.197 0.196 0.211 0.335 0.306 0.305\n",
      " 0.073 0.061 0.037 0.054 0.062 0.05  0.04  0.11  0.059 0.032 0.052 0.059\n",
      " 0.045 0.041 0.06  0.056 0.033 0.061 0.098 0.044 0.046 0.062 0.056 0.123\n",
      " 0.065 0.043 0.061 0.06  0.028 0.06  0.058 0.035 0.053 0.059 0.041 0.047\n",
      " 0.06  0.066 0.206 0.195 0.188 0.245 0.284 0.282 0.214 0.2   0.263 0.103\n",
      " 0.208 0.208 0.208 0.208 0.208 0.208 0.208 0.208 0.208 0.208 0.208 0.208\n",
      " 0.208 0.208 0.208 0.208 0.208 0.208 0.208 0.208 0.208 0.208 0.208 0.208\n",
      " 0.064 0.039 0.052 0.061 0.053 0.037 0.102 0.057 0.038 0.046 0.057 0.051\n",
      " 0.032 0.057 0.057 0.048 0.094 0.059 0.04  0.048 0.058 0.043 0.043 0.057\n",
      " 0.29  0.267 0.244 0.276 0.232 0.135 0.093 0.093 0.066 0.089 0.093 0.072\n",
      " 0.184 0.218 0.167 0.166 0.138 0.179 0.173 0.211 0.208 0.242 0.233 0.072\n",
      " 0.035 0.064 0.063 0.04  0.049 0.061 0.051 0.039 0.059 0.059 0.037 0.05\n",
      " 0.059 0.083 0.176 0.238 0.312 0.169 0.251 0.362 0.324 0.318 0.25  0.263\n",
      " 0.091 0.088 0.107 0.073 0.094 0.1   0.072 0.09  0.097 0.073 0.085 0.094\n",
      " 0.08  0.076 0.093 0.088 0.068 0.094 0.095 0.25  0.3   0.248 0.243 0.098\n",
      " 0.31  0.255 0.211 0.207 0.202 0.202 0.172 0.193 0.181 0.176 0.187 0.223\n",
      " 0.322 0.289 0.219 0.187 0.219 0.224 0.226 0.22  0.216 0.215 0.215 0.215\n",
      " 0.174 0.089 0.083 0.071 0.097 0.101 0.076 0.112 0.26  0.346 0.226 0.154\n",
      " 0.145 0.201 0.275 0.254 0.243 0.224 0.081 0.093 0.104 0.394 0.463 0.336\n",
      " 0.048 0.075 0.078 0.049 0.066 0.073 0.056 0.047 0.057 0.048 0.038 0.057\n",
      " 0.052 0.032 0.057 0.054 0.031 0.142 0.242 0.26  0.26  0.267 0.235 0.229\n",
      " 0.257 0.181 0.174 0.171 0.174 0.171 0.172 0.217 0.188 0.189 0.215 0.223\n",
      " 0.218 0.216 0.217 0.188 0.207 0.194 0.187 0.253 0.336 0.413 0.399 0.178\n",
      " 0.176 0.175 0.211 0.211 0.204 0.202 0.176 0.241 0.175 0.174 0.178 0.184\n",
      " 0.185 0.175 0.177 0.175 0.175 0.176 0.215 0.201 0.206 0.2   0.197 0.197\n",
      " 0.275 0.201 0.176 0.21  0.199 0.202 0.199 0.252 0.213 0.173 0.186 0.188\n",
      " 0.171 0.191 0.175 0.168 0.196 0.177 0.218 0.2   0.206 0.202 0.201 0.196]\n"
     ]
    }
   ],
   "source": [
    "# Set Tranining Data\n",
    "training_samples = np.array(training_samples)\n",
    "\n",
    "train_X = training_samples[:,:-1]\n",
    "train_y = training_samples[:,-1]\n",
    "\n",
    "# Set Test Data\n",
    "test_samples = np.array(test_samples)\n",
    "test_X = test_samples[:,:-1]\n",
    "test_y = test_samples[:,-1]\n",
    "\n",
    "print(\"Input Data For Training\")\n",
    "print(np.array(train_X))\n",
    "print()\n",
    "print(\"Output Data For Training\")\n",
    "print(np.array(train_y))\n",
    "\n",
    "print(\"Input Data For Test\")\n",
    "print(np.array(test_X))\n",
    "print()\n",
    "print(\"Output Data For Test\")\n",
    "print(np.array(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "a1494d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# model.add(Embedding(value_size, input_length=28))\n",
    "model.add(LSTM(128, input_shape=(28, 1),return_sequences=True, activation='softmax'))\n",
    "model.add(Dense(1,activation='softmax'))\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "efd18ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1872 (1872, 28) [[  0   0   0 ...   2  20  73]\n",
      " [  0   0   0 ...  20  73 342]\n",
      " [  0   0   0 ...  73 342 338]\n",
      " ...\n",
      " [  0   0   1 ...  39  62  60]\n",
      " [  0   1   2 ...  62  60  31]\n",
      " [  1   2   6 ...  60  31  57]]\n",
      "1872 (1872, 28, 1) [[[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  ...\n",
      "  [  2]\n",
      "  [ 20]\n",
      "  [ 73]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  ...\n",
      "  [ 20]\n",
      "  [ 73]\n",
      "  [342]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  ...\n",
      "  [ 73]\n",
      "  [342]\n",
      "  [338]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  1]\n",
      "  ...\n",
      "  [ 39]\n",
      "  [ 62]\n",
      "  [ 60]]\n",
      "\n",
      " [[  0]\n",
      "  [  1]\n",
      "  [  2]\n",
      "  ...\n",
      "  [ 62]\n",
      "  [ 60]\n",
      "  [ 31]]\n",
      "\n",
      " [[  1]\n",
      "  [  2]\n",
      "  [  6]\n",
      "  ...\n",
      "  [ 60]\n",
      "  [ 31]\n",
      "  [ 57]]]\n",
      "1872 (1872,) [342 338 325 ...  31  57  59]\n"
     ]
    }
   ],
   "source": [
    "print(len(train_X), train_X.shape, train_X)\n",
    "train_X = train_X.reshape(train_X.shape[0], train_X.shape[1], 1)\n",
    "print(len(train_X), train_X.shape, train_X)\n",
    "print(len(train_y), train_y.shape, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "4b808082",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1872/1872 - 7s - loss: 32817.1172 - accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "1872/1872 - 6s - loss: 32817.1211 - accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "1872/1872 - 6s - loss: 32817.1211 - accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "1872/1872 - 6s - loss: 32817.1211 - accuracy: 0.0000e+00\n",
      "Epoch 5/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-333-0b3ad997b7ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_X, train_y, epochs=200, batch_size=1 ,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "05087568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0]]\n",
      "\n",
      " [[  0]]\n",
      "\n",
      " [[  0]]\n",
      "\n",
      " [[  0]]\n",
      "\n",
      " [[  0]]\n",
      "\n",
      " [[  0]]\n",
      "\n",
      " [[  0]]\n",
      "\n",
      " [[  0]]\n",
      "\n",
      " [[  0]]\n",
      "\n",
      " [[  0]]\n",
      "\n",
      " [[  0]]\n",
      "\n",
      " [[  0]]\n",
      "\n",
      " [[  0]]\n",
      "\n",
      " [[  0]]\n",
      "\n",
      " [[  0]]\n",
      "\n",
      " [[  0]]\n",
      "\n",
      " [[  0]]\n",
      "\n",
      " [[  0]]\n",
      "\n",
      " [[  0]]\n",
      "\n",
      " [[  0]]\n",
      "\n",
      " [[  0]]\n",
      "\n",
      " [[  1]]\n",
      "\n",
      " [[  3]]\n",
      "\n",
      " [[  2]]\n",
      "\n",
      " [[  8]]\n",
      "\n",
      " [[ 55]]\n",
      "\n",
      " [[162]]\n",
      "\n",
      " [[160]]]\n",
      "[[[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]\n",
      "\n",
      " [[1.]]]\n"
     ]
    }
   ],
   "source": [
    "test = test_X[2]\n",
    "test = test.reshape(28,1,1)\n",
    "print(test)\n",
    "result = model.predict(test, verbose=0)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "66044859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0 ...   3  11  62]\n",
      " [  0   0   0 ...  11  62 184]\n",
      " [  0   0   0 ...  62 184 236]\n",
      " ...\n",
      " [  0   0   1 ...  39  62  60]\n",
      " [  0   1   2 ...  62  60  31]\n",
      " [  1   2   6 ...  60  31  57]]\n",
      "[184 236 168 ...  31  57  59]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(train_X)\n",
    "print(train_y)\n",
    "\n",
    "one_hot_y = to_categorical(train_y,num_classes= value_size)\n",
    "print(one_hot_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "cf947e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 28, 10)            18720     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 32)                5504      \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1872)              61776     \n",
      "=================================================================\n",
      "Total params: 86,000\n",
      "Trainable params: 86,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Embedding(value_size, 10, input_length=28))\n",
    "model_2.add(LSTM(32))\n",
    "model_2.add(Dense(value_size, activation='softmax'))\n",
    "model_2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "7bb7f81e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "59/59 - 1s - loss: 7.1447 - accuracy: 0.0176\n",
      "Epoch 2/600\n",
      "59/59 - 0s - loss: 5.7161 - accuracy: 0.0321\n",
      "Epoch 3/600\n",
      "59/59 - 0s - loss: 5.4933 - accuracy: 0.0321\n",
      "Epoch 4/600\n",
      "59/59 - 0s - loss: 5.4561 - accuracy: 0.0321\n",
      "Epoch 5/600\n",
      "59/59 - 0s - loss: 5.4388 - accuracy: 0.0321\n",
      "Epoch 6/600\n",
      "59/59 - 0s - loss: 5.4287 - accuracy: 0.0321\n",
      "Epoch 7/600\n",
      "59/59 - 0s - loss: 5.4242 - accuracy: 0.0321\n",
      "Epoch 8/600\n",
      "59/59 - 0s - loss: 5.4203 - accuracy: 0.0321\n",
      "Epoch 9/600\n",
      "59/59 - 0s - loss: 5.4160 - accuracy: 0.0321\n",
      "Epoch 10/600\n",
      "59/59 - 0s - loss: 5.4151 - accuracy: 0.0321\n",
      "Epoch 11/600\n",
      "59/59 - 0s - loss: 5.4132 - accuracy: 0.0321\n",
      "Epoch 12/600\n",
      "59/59 - 0s - loss: 5.4127 - accuracy: 0.0321\n",
      "Epoch 13/600\n",
      "59/59 - 0s - loss: 5.4132 - accuracy: 0.0321\n",
      "Epoch 14/600\n",
      "59/59 - 0s - loss: 5.4115 - accuracy: 0.0321\n",
      "Epoch 15/600\n",
      "59/59 - 0s - loss: 5.4093 - accuracy: 0.0321\n",
      "Epoch 16/600\n",
      "59/59 - 0s - loss: 5.4104 - accuracy: 0.0321\n",
      "Epoch 17/600\n",
      "59/59 - 0s - loss: 5.4091 - accuracy: 0.0321\n",
      "Epoch 18/600\n",
      "59/59 - 0s - loss: 5.4087 - accuracy: 0.0321\n",
      "Epoch 19/600\n",
      "59/59 - 0s - loss: 5.4077 - accuracy: 0.0321\n",
      "Epoch 20/600\n",
      "59/59 - 0s - loss: 5.4071 - accuracy: 0.0321\n",
      "Epoch 21/600\n",
      "59/59 - 0s - loss: 5.4097 - accuracy: 0.0321\n",
      "Epoch 22/600\n",
      "59/59 - 0s - loss: 5.4085 - accuracy: 0.0321\n",
      "Epoch 23/600\n",
      "59/59 - 0s - loss: 5.4059 - accuracy: 0.0321\n",
      "Epoch 24/600\n",
      "59/59 - 0s - loss: 5.4076 - accuracy: 0.0321\n",
      "Epoch 25/600\n",
      "59/59 - 0s - loss: 5.4046 - accuracy: 0.0321\n",
      "Epoch 26/600\n",
      "59/59 - 0s - loss: 5.4045 - accuracy: 0.0321\n",
      "Epoch 27/600\n",
      "59/59 - 0s - loss: 5.4058 - accuracy: 0.0321\n",
      "Epoch 28/600\n",
      "59/59 - 0s - loss: 5.4040 - accuracy: 0.0321\n",
      "Epoch 29/600\n",
      "59/59 - 0s - loss: 5.4040 - accuracy: 0.0321\n",
      "Epoch 30/600\n",
      "59/59 - 0s - loss: 5.4014 - accuracy: 0.0321\n",
      "Epoch 31/600\n",
      "59/59 - 0s - loss: 5.4008 - accuracy: 0.0321\n",
      "Epoch 32/600\n",
      "59/59 - 0s - loss: 5.3996 - accuracy: 0.0321\n",
      "Epoch 33/600\n",
      "59/59 - 0s - loss: 5.3985 - accuracy: 0.0321\n",
      "Epoch 34/600\n",
      "59/59 - 0s - loss: 5.3956 - accuracy: 0.0321\n",
      "Epoch 35/600\n",
      "59/59 - 0s - loss: 5.3949 - accuracy: 0.0321\n",
      "Epoch 36/600\n",
      "59/59 - 0s - loss: 5.3938 - accuracy: 0.0321\n",
      "Epoch 37/600\n",
      "59/59 - 0s - loss: 5.3929 - accuracy: 0.0321\n",
      "Epoch 38/600\n",
      "59/59 - 0s - loss: 5.3933 - accuracy: 0.0321\n",
      "Epoch 39/600\n",
      "59/59 - 0s - loss: 5.3936 - accuracy: 0.0321\n",
      "Epoch 40/600\n",
      "59/59 - 0s - loss: 5.3920 - accuracy: 0.0321\n",
      "Epoch 41/600\n",
      "59/59 - 0s - loss: 5.3921 - accuracy: 0.0321\n",
      "Epoch 42/600\n",
      "59/59 - 0s - loss: 5.3902 - accuracy: 0.0321\n",
      "Epoch 43/600\n",
      "59/59 - 0s - loss: 5.3897 - accuracy: 0.0321\n",
      "Epoch 44/600\n",
      "59/59 - 0s - loss: 5.3882 - accuracy: 0.0321\n",
      "Epoch 45/600\n",
      "59/59 - 0s - loss: 5.3891 - accuracy: 0.0321\n",
      "Epoch 46/600\n",
      "59/59 - 0s - loss: 5.3868 - accuracy: 0.0321\n",
      "Epoch 47/600\n",
      "59/59 - 0s - loss: 5.3874 - accuracy: 0.0321\n",
      "Epoch 48/600\n",
      "59/59 - 0s - loss: 5.3850 - accuracy: 0.0321\n",
      "Epoch 49/600\n",
      "59/59 - 0s - loss: 5.3826 - accuracy: 0.0321\n",
      "Epoch 50/600\n",
      "59/59 - 0s - loss: 5.3831 - accuracy: 0.0321\n",
      "Epoch 51/600\n",
      "59/59 - 0s - loss: 5.3798 - accuracy: 0.0321\n",
      "Epoch 52/600\n",
      "59/59 - 0s - loss: 5.3691 - accuracy: 0.0321\n",
      "Epoch 53/600\n",
      "59/59 - 0s - loss: 5.3593 - accuracy: 0.0321\n",
      "Epoch 54/600\n",
      "59/59 - 0s - loss: 5.3534 - accuracy: 0.0321\n",
      "Epoch 55/600\n",
      "59/59 - 0s - loss: 5.3335 - accuracy: 0.0321\n",
      "Epoch 56/600\n",
      "59/59 - 0s - loss: 5.3138 - accuracy: 0.0321\n",
      "Epoch 57/600\n",
      "59/59 - 0s - loss: 5.2948 - accuracy: 0.0321\n",
      "Epoch 58/600\n",
      "59/59 - 0s - loss: 5.2723 - accuracy: 0.0321\n",
      "Epoch 59/600\n",
      "59/59 - 0s - loss: 5.2377 - accuracy: 0.0321\n",
      "Epoch 60/600\n",
      "59/59 - 0s - loss: 5.2050 - accuracy: 0.0326\n",
      "Epoch 61/600\n",
      "59/59 - 0s - loss: 5.1695 - accuracy: 0.0331\n",
      "Epoch 62/600\n",
      "59/59 - 0s - loss: 5.1475 - accuracy: 0.0347\n",
      "Epoch 63/600\n",
      "59/59 - 0s - loss: 5.1302 - accuracy: 0.0342\n",
      "Epoch 64/600\n",
      "59/59 - 0s - loss: 5.0827 - accuracy: 0.0374\n",
      "Epoch 65/600\n",
      "59/59 - 0s - loss: 5.0626 - accuracy: 0.0422\n",
      "Epoch 66/600\n",
      "59/59 - 0s - loss: 5.0340 - accuracy: 0.0401\n",
      "Epoch 67/600\n",
      "59/59 - 0s - loss: 5.0125 - accuracy: 0.0411\n",
      "Epoch 68/600\n",
      "59/59 - 0s - loss: 4.9822 - accuracy: 0.0401\n",
      "Epoch 69/600\n",
      "59/59 - 0s - loss: 4.9575 - accuracy: 0.0385\n",
      "Epoch 70/600\n",
      "59/59 - 0s - loss: 4.9355 - accuracy: 0.0443\n",
      "Epoch 71/600\n",
      "59/59 - 0s - loss: 4.9234 - accuracy: 0.0454\n",
      "Epoch 72/600\n",
      "59/59 - 0s - loss: 4.9117 - accuracy: 0.0454\n",
      "Epoch 73/600\n",
      "59/59 - 0s - loss: 4.8839 - accuracy: 0.0475\n",
      "Epoch 74/600\n",
      "59/59 - 0s - loss: 4.8713 - accuracy: 0.0427\n",
      "Epoch 75/600\n",
      "59/59 - 0s - loss: 4.8587 - accuracy: 0.0449\n",
      "Epoch 76/600\n",
      "59/59 - 0s - loss: 4.8389 - accuracy: 0.0465\n",
      "Epoch 77/600\n",
      "59/59 - 0s - loss: 4.8295 - accuracy: 0.0486\n",
      "Epoch 78/600\n",
      "59/59 - 0s - loss: 4.8218 - accuracy: 0.0459\n",
      "Epoch 79/600\n",
      "59/59 - 0s - loss: 4.8007 - accuracy: 0.0507\n",
      "Epoch 80/600\n",
      "59/59 - 0s - loss: 4.7845 - accuracy: 0.0497\n",
      "Epoch 81/600\n",
      "59/59 - 0s - loss: 4.7672 - accuracy: 0.0491\n",
      "Epoch 82/600\n",
      "59/59 - 0s - loss: 4.7542 - accuracy: 0.0524\n",
      "Epoch 83/600\n",
      "59/59 - 0s - loss: 4.7305 - accuracy: 0.0566\n",
      "Epoch 84/600\n",
      "59/59 - 0s - loss: 4.7228 - accuracy: 0.0566\n",
      "Epoch 85/600\n",
      "59/59 - 0s - loss: 4.7056 - accuracy: 0.0545\n",
      "Epoch 86/600\n",
      "59/59 - 0s - loss: 4.7062 - accuracy: 0.0577\n",
      "Epoch 87/600\n",
      "59/59 - 0s - loss: 4.6938 - accuracy: 0.0588\n",
      "Epoch 88/600\n",
      "59/59 - 0s - loss: 4.6739 - accuracy: 0.0577\n",
      "Epoch 89/600\n",
      "59/59 - 0s - loss: 4.6568 - accuracy: 0.0609\n",
      "Epoch 90/600\n",
      "59/59 - 0s - loss: 4.6486 - accuracy: 0.0593\n",
      "Epoch 91/600\n",
      "59/59 - 0s - loss: 4.6353 - accuracy: 0.0604\n",
      "Epoch 92/600\n",
      "59/59 - 0s - loss: 4.6383 - accuracy: 0.0582\n",
      "Epoch 93/600\n",
      "59/59 - 0s - loss: 4.6272 - accuracy: 0.0598\n",
      "Epoch 94/600\n",
      "59/59 - 0s - loss: 4.6127 - accuracy: 0.0609\n",
      "Epoch 95/600\n",
      "59/59 - 0s - loss: 4.5968 - accuracy: 0.0620\n",
      "Epoch 96/600\n",
      "59/59 - 0s - loss: 4.5823 - accuracy: 0.0609\n",
      "Epoch 97/600\n",
      "59/59 - 0s - loss: 4.5811 - accuracy: 0.0625\n",
      "Epoch 98/600\n",
      "59/59 - 0s - loss: 4.5961 - accuracy: 0.0636\n",
      "Epoch 99/600\n",
      "59/59 - 0s - loss: 4.5802 - accuracy: 0.0646\n",
      "Epoch 100/600\n",
      "59/59 - 0s - loss: 4.5543 - accuracy: 0.0652\n",
      "Epoch 101/600\n",
      "59/59 - 0s - loss: 4.5456 - accuracy: 0.0641\n",
      "Epoch 102/600\n",
      "59/59 - 0s - loss: 4.5333 - accuracy: 0.0646\n",
      "Epoch 103/600\n",
      "59/59 - 0s - loss: 4.5131 - accuracy: 0.0652\n",
      "Epoch 104/600\n",
      "59/59 - 0s - loss: 4.5098 - accuracy: 0.0657\n",
      "Epoch 105/600\n",
      "59/59 - 0s - loss: 4.5094 - accuracy: 0.0678\n",
      "Epoch 106/600\n",
      "59/59 - 0s - loss: 4.4892 - accuracy: 0.0657\n",
      "Epoch 107/600\n",
      "59/59 - 0s - loss: 4.4853 - accuracy: 0.0678\n",
      "Epoch 108/600\n",
      "59/59 - 0s - loss: 4.4836 - accuracy: 0.0689\n",
      "Epoch 109/600\n",
      "59/59 - 0s - loss: 4.4750 - accuracy: 0.0689\n",
      "Epoch 110/600\n",
      "59/59 - 0s - loss: 4.4540 - accuracy: 0.0710\n",
      "Epoch 111/600\n",
      "59/59 - 0s - loss: 4.4383 - accuracy: 0.0721\n",
      "Epoch 112/600\n",
      "59/59 - 0s - loss: 4.4418 - accuracy: 0.0737\n",
      "Epoch 113/600\n",
      "59/59 - 0s - loss: 4.4506 - accuracy: 0.0710\n",
      "Epoch 114/600\n",
      "59/59 - 0s - loss: 4.4325 - accuracy: 0.0769\n",
      "Epoch 115/600\n",
      "59/59 - 0s - loss: 4.4077 - accuracy: 0.0716\n",
      "Epoch 116/600\n",
      "59/59 - 0s - loss: 4.4013 - accuracy: 0.0785\n",
      "Epoch 117/600\n",
      "59/59 - 0s - loss: 4.4000 - accuracy: 0.0737\n",
      "Epoch 118/600\n",
      "59/59 - 0s - loss: 4.3953 - accuracy: 0.0737\n",
      "Epoch 119/600\n",
      "59/59 - 0s - loss: 4.3754 - accuracy: 0.0791\n",
      "Epoch 120/600\n",
      "59/59 - 0s - loss: 4.3765 - accuracy: 0.0743\n",
      "Epoch 121/600\n",
      "59/59 - 0s - loss: 4.3622 - accuracy: 0.0769\n",
      "Epoch 122/600\n",
      "59/59 - 0s - loss: 4.3600 - accuracy: 0.0780\n",
      "Epoch 123/600\n",
      "59/59 - 0s - loss: 4.3516 - accuracy: 0.0759\n",
      "Epoch 124/600\n",
      "59/59 - 0s - loss: 4.3393 - accuracy: 0.0817\n",
      "Epoch 125/600\n",
      "59/59 - 0s - loss: 4.3490 - accuracy: 0.0796\n",
      "Epoch 126/600\n",
      "59/59 - 0s - loss: 4.3205 - accuracy: 0.0801\n",
      "Epoch 127/600\n",
      "59/59 - 0s - loss: 4.3075 - accuracy: 0.0844\n",
      "Epoch 128/600\n",
      "59/59 - 0s - loss: 4.3024 - accuracy: 0.0812\n",
      "Epoch 129/600\n",
      "59/59 - 0s - loss: 4.2998 - accuracy: 0.0812\n",
      "Epoch 130/600\n",
      "59/59 - 0s - loss: 4.3211 - accuracy: 0.0796\n",
      "Epoch 131/600\n",
      "59/59 - 0s - loss: 4.2868 - accuracy: 0.0865\n",
      "Epoch 132/600\n",
      "59/59 - 0s - loss: 4.2782 - accuracy: 0.0876\n",
      "Epoch 133/600\n",
      "59/59 - 0s - loss: 4.2619 - accuracy: 0.0881\n",
      "Epoch 134/600\n",
      "59/59 - 0s - loss: 4.2866 - accuracy: 0.0849\n",
      "Epoch 135/600\n",
      "59/59 - 0s - loss: 4.2574 - accuracy: 0.0865\n",
      "Epoch 136/600\n",
      "59/59 - 0s - loss: 4.2423 - accuracy: 0.0871\n",
      "Epoch 137/600\n",
      "59/59 - 0s - loss: 4.2479 - accuracy: 0.0823\n",
      "Epoch 138/600\n",
      "59/59 - 0s - loss: 4.2346 - accuracy: 0.0823\n",
      "Epoch 139/600\n",
      "59/59 - 0s - loss: 4.2248 - accuracy: 0.0828\n",
      "Epoch 140/600\n",
      "59/59 - 0s - loss: 4.2126 - accuracy: 0.0903\n",
      "Epoch 141/600\n",
      "59/59 - 0s - loss: 4.2151 - accuracy: 0.0903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/600\n",
      "59/59 - 0s - loss: 4.2126 - accuracy: 0.0919\n",
      "Epoch 143/600\n",
      "59/59 - 0s - loss: 4.1972 - accuracy: 0.0881\n",
      "Epoch 144/600\n",
      "59/59 - 0s - loss: 4.1779 - accuracy: 0.0913\n",
      "Epoch 145/600\n",
      "59/59 - 0s - loss: 4.1790 - accuracy: 0.0940\n",
      "Epoch 146/600\n",
      "59/59 - 0s - loss: 4.1602 - accuracy: 0.0962\n",
      "Epoch 147/600\n",
      "59/59 - 0s - loss: 4.1610 - accuracy: 0.0908\n",
      "Epoch 148/600\n",
      "59/59 - 0s - loss: 4.1630 - accuracy: 0.0908\n",
      "Epoch 149/600\n",
      "59/59 - 0s - loss: 4.1601 - accuracy: 0.0903\n",
      "Epoch 150/600\n",
      "59/59 - 0s - loss: 4.1587 - accuracy: 0.0908\n",
      "Epoch 151/600\n",
      "59/59 - 0s - loss: 4.1471 - accuracy: 0.0929\n",
      "Epoch 152/600\n",
      "59/59 - 0s - loss: 4.1283 - accuracy: 0.0962\n",
      "Epoch 153/600\n",
      "59/59 - 0s - loss: 4.1260 - accuracy: 0.0994\n",
      "Epoch 154/600\n",
      "59/59 - 0s - loss: 4.1354 - accuracy: 0.0967\n",
      "Epoch 155/600\n",
      "59/59 - 0s - loss: 4.1149 - accuracy: 0.0956\n",
      "Epoch 156/600\n",
      "59/59 - 0s - loss: 4.1152 - accuracy: 0.0988\n",
      "Epoch 157/600\n",
      "59/59 - 0s - loss: 4.1087 - accuracy: 0.0924\n",
      "Epoch 158/600\n",
      "59/59 - 0s - loss: 4.1021 - accuracy: 0.0978\n",
      "Epoch 159/600\n",
      "59/59 - 0s - loss: 4.0805 - accuracy: 0.0972\n",
      "Epoch 160/600\n",
      "59/59 - 0s - loss: 4.1034 - accuracy: 0.1004\n",
      "Epoch 161/600\n",
      "59/59 - 0s - loss: 4.1138 - accuracy: 0.0978\n",
      "Epoch 162/600\n",
      "59/59 - 0s - loss: 4.0912 - accuracy: 0.0919\n",
      "Epoch 163/600\n",
      "59/59 - 0s - loss: 4.0758 - accuracy: 0.0983\n",
      "Epoch 164/600\n",
      "59/59 - 0s - loss: 4.0703 - accuracy: 0.1031\n",
      "Epoch 165/600\n",
      "59/59 - 0s - loss: 4.0754 - accuracy: 0.0956\n",
      "Epoch 166/600\n",
      "59/59 - 0s - loss: 4.0585 - accuracy: 0.1042\n",
      "Epoch 167/600\n",
      "59/59 - 0s - loss: 4.0378 - accuracy: 0.1047\n",
      "Epoch 168/600\n",
      "59/59 - 0s - loss: 4.0388 - accuracy: 0.1031\n",
      "Epoch 169/600\n",
      "59/59 - 0s - loss: 4.0217 - accuracy: 0.1074\n",
      "Epoch 170/600\n",
      "59/59 - 0s - loss: 4.2532 - accuracy: 0.0817\n",
      "Epoch 171/600\n",
      "59/59 - 0s - loss: 4.1004 - accuracy: 0.0972\n",
      "Epoch 172/600\n",
      "59/59 - 0s - loss: 4.0477 - accuracy: 0.1042\n",
      "Epoch 173/600\n",
      "59/59 - 0s - loss: 4.0155 - accuracy: 0.1122\n",
      "Epoch 174/600\n",
      "59/59 - 0s - loss: 4.0290 - accuracy: 0.1084\n",
      "Epoch 175/600\n",
      "59/59 - 0s - loss: 4.0005 - accuracy: 0.1079\n",
      "Epoch 176/600\n",
      "59/59 - 0s - loss: 4.0142 - accuracy: 0.1042\n",
      "Epoch 177/600\n",
      "59/59 - 0s - loss: 3.9988 - accuracy: 0.1084\n",
      "Epoch 178/600\n",
      "59/59 - 0s - loss: 4.2244 - accuracy: 0.0929\n",
      "Epoch 179/600\n",
      "59/59 - 0s - loss: 4.0604 - accuracy: 0.1063\n",
      "Epoch 180/600\n",
      "59/59 - 0s - loss: 4.0090 - accuracy: 0.1090\n",
      "Epoch 181/600\n",
      "59/59 - 0s - loss: 3.9808 - accuracy: 0.1116\n",
      "Epoch 182/600\n",
      "59/59 - 0s - loss: 3.9786 - accuracy: 0.1106\n",
      "Epoch 183/600\n",
      "59/59 - 0s - loss: 3.9679 - accuracy: 0.1143\n",
      "Epoch 184/600\n",
      "59/59 - 0s - loss: 3.9485 - accuracy: 0.1159\n",
      "Epoch 185/600\n",
      "59/59 - 0s - loss: 3.9471 - accuracy: 0.1138\n",
      "Epoch 186/600\n",
      "59/59 - 0s - loss: 3.9311 - accuracy: 0.1165\n",
      "Epoch 187/600\n",
      "59/59 - 0s - loss: 3.9272 - accuracy: 0.1202\n",
      "Epoch 188/600\n",
      "59/59 - 0s - loss: 3.9462 - accuracy: 0.1165\n",
      "Epoch 189/600\n",
      "59/59 - 0s - loss: 3.9519 - accuracy: 0.1159\n",
      "Epoch 190/600\n",
      "59/59 - 0s - loss: 3.9576 - accuracy: 0.1090\n",
      "Epoch 191/600\n",
      "59/59 - 0s - loss: 3.9109 - accuracy: 0.1191\n",
      "Epoch 192/600\n",
      "59/59 - 0s - loss: 3.9012 - accuracy: 0.1181\n",
      "Epoch 193/600\n",
      "59/59 - 0s - loss: 3.9017 - accuracy: 0.1202\n",
      "Epoch 194/600\n",
      "59/59 - 0s - loss: 3.8984 - accuracy: 0.1197\n",
      "Epoch 195/600\n",
      "59/59 - 0s - loss: 3.9199 - accuracy: 0.1181\n",
      "Epoch 196/600\n",
      "59/59 - 0s - loss: 3.9344 - accuracy: 0.1138\n",
      "Epoch 197/600\n",
      "59/59 - 0s - loss: 3.8918 - accuracy: 0.1218\n",
      "Epoch 198/600\n",
      "59/59 - 0s - loss: 3.8750 - accuracy: 0.1239\n",
      "Epoch 199/600\n",
      "59/59 - 0s - loss: 3.8709 - accuracy: 0.1255\n",
      "Epoch 200/600\n",
      "59/59 - 0s - loss: 3.8721 - accuracy: 0.1261\n",
      "Epoch 201/600\n",
      "59/59 - 0s - loss: 3.8806 - accuracy: 0.1197\n",
      "Epoch 202/600\n",
      "59/59 - 0s - loss: 3.8805 - accuracy: 0.1186\n",
      "Epoch 203/600\n",
      "59/59 - 0s - loss: 3.9910 - accuracy: 0.1143\n",
      "Epoch 204/600\n",
      "59/59 - 0s - loss: 3.8883 - accuracy: 0.1191\n",
      "Epoch 205/600\n",
      "59/59 - 0s - loss: 3.8609 - accuracy: 0.1229\n",
      "Epoch 206/600\n",
      "59/59 - 0s - loss: 3.8648 - accuracy: 0.1245\n",
      "Epoch 207/600\n",
      "59/59 - 0s - loss: 3.8644 - accuracy: 0.1261\n",
      "Epoch 208/600\n",
      "59/59 - 0s - loss: 3.8926 - accuracy: 0.1181\n",
      "Epoch 209/600\n",
      "59/59 - 0s - loss: 3.8559 - accuracy: 0.1197\n",
      "Epoch 210/600\n",
      "59/59 - 0s - loss: 3.8399 - accuracy: 0.1239\n",
      "Epoch 211/600\n",
      "59/59 - 0s - loss: 3.8211 - accuracy: 0.1282\n",
      "Epoch 212/600\n",
      "59/59 - 0s - loss: 3.8324 - accuracy: 0.1314\n",
      "Epoch 213/600\n",
      "59/59 - 0s - loss: 3.8043 - accuracy: 0.1277\n",
      "Epoch 214/600\n",
      "59/59 - 0s - loss: 3.8145 - accuracy: 0.1325\n",
      "Epoch 215/600\n",
      "59/59 - 0s - loss: 3.8274 - accuracy: 0.1261\n",
      "Epoch 216/600\n",
      "59/59 - 0s - loss: 3.7931 - accuracy: 0.1314\n",
      "Epoch 217/600\n",
      "59/59 - 0s - loss: 3.8094 - accuracy: 0.1213\n",
      "Epoch 218/600\n",
      "59/59 - 0s - loss: 3.7828 - accuracy: 0.1335\n",
      "Epoch 219/600\n",
      "59/59 - 0s - loss: 3.7686 - accuracy: 0.1341\n",
      "Epoch 220/600\n",
      "59/59 - 0s - loss: 3.7797 - accuracy: 0.1341\n",
      "Epoch 221/600\n",
      "59/59 - 0s - loss: 3.7631 - accuracy: 0.1368\n",
      "Epoch 222/600\n",
      "59/59 - 0s - loss: 3.7901 - accuracy: 0.1335\n",
      "Epoch 223/600\n",
      "59/59 - 0s - loss: 3.8052 - accuracy: 0.1293\n",
      "Epoch 224/600\n",
      "59/59 - 0s - loss: 3.7594 - accuracy: 0.1362\n",
      "Epoch 225/600\n",
      "59/59 - 0s - loss: 3.7628 - accuracy: 0.1368\n",
      "Epoch 226/600\n",
      "59/59 - 0s - loss: 3.7541 - accuracy: 0.1384\n",
      "Epoch 227/600\n",
      "59/59 - 0s - loss: 3.7420 - accuracy: 0.1373\n",
      "Epoch 228/600\n",
      "59/59 - 0s - loss: 3.7308 - accuracy: 0.1384\n",
      "Epoch 229/600\n",
      "59/59 - 0s - loss: 3.7446 - accuracy: 0.1373\n",
      "Epoch 230/600\n",
      "59/59 - 0s - loss: 3.7388 - accuracy: 0.1442\n",
      "Epoch 231/600\n",
      "59/59 - 0s - loss: 3.7507 - accuracy: 0.1335\n",
      "Epoch 232/600\n",
      "59/59 - 0s - loss: 3.8841 - accuracy: 0.1170\n",
      "Epoch 233/600\n",
      "59/59 - 0s - loss: 3.8171 - accuracy: 0.1277\n",
      "Epoch 234/600\n",
      "59/59 - 0s - loss: 3.7431 - accuracy: 0.1346\n",
      "Epoch 235/600\n",
      "59/59 - 0s - loss: 3.7343 - accuracy: 0.1325\n",
      "Epoch 236/600\n",
      "59/59 - 0s - loss: 3.7482 - accuracy: 0.1384\n",
      "Epoch 237/600\n",
      "59/59 - 0s - loss: 3.7638 - accuracy: 0.1351\n",
      "Epoch 238/600\n",
      "59/59 - 0s - loss: 3.8498 - accuracy: 0.1229\n",
      "Epoch 239/600\n",
      "59/59 - 0s - loss: 3.7742 - accuracy: 0.1261\n",
      "Epoch 240/600\n",
      "59/59 - 0s - loss: 3.6983 - accuracy: 0.1405\n",
      "Epoch 241/600\n",
      "59/59 - 0s - loss: 3.7072 - accuracy: 0.1351\n",
      "Epoch 242/600\n",
      "59/59 - 0s - loss: 3.7046 - accuracy: 0.1410\n",
      "Epoch 243/600\n",
      "59/59 - 0s - loss: 3.6753 - accuracy: 0.1405\n",
      "Epoch 244/600\n",
      "59/59 - 0s - loss: 3.6842 - accuracy: 0.1448\n",
      "Epoch 245/600\n",
      "59/59 - 0s - loss: 3.6796 - accuracy: 0.1458\n",
      "Epoch 246/600\n",
      "59/59 - 0s - loss: 3.6677 - accuracy: 0.1405\n",
      "Epoch 247/600\n",
      "59/59 - 0s - loss: 3.6968 - accuracy: 0.1373\n",
      "Epoch 248/600\n",
      "59/59 - 0s - loss: 3.7474 - accuracy: 0.1346\n",
      "Epoch 249/600\n",
      "59/59 - 0s - loss: 3.8039 - accuracy: 0.1298\n",
      "Epoch 250/600\n",
      "59/59 - 0s - loss: 3.7104 - accuracy: 0.1410\n",
      "Epoch 251/600\n",
      "59/59 - 0s - loss: 3.6523 - accuracy: 0.1437\n",
      "Epoch 252/600\n",
      "59/59 - 0s - loss: 3.7281 - accuracy: 0.1357\n",
      "Epoch 253/600\n",
      "59/59 - 0s - loss: 3.6916 - accuracy: 0.1421\n",
      "Epoch 254/600\n",
      "59/59 - 0s - loss: 3.6337 - accuracy: 0.1432\n",
      "Epoch 255/600\n",
      "59/59 - 0s - loss: 3.6383 - accuracy: 0.1512\n",
      "Epoch 256/600\n",
      "59/59 - 0s - loss: 3.6186 - accuracy: 0.1490\n",
      "Epoch 257/600\n",
      "59/59 - 0s - loss: 3.6173 - accuracy: 0.1464\n",
      "Epoch 258/600\n",
      "59/59 - 0s - loss: 3.6101 - accuracy: 0.1496\n",
      "Epoch 259/600\n",
      "59/59 - 0s - loss: 3.6558 - accuracy: 0.1464\n",
      "Epoch 260/600\n",
      "59/59 - 0s - loss: 3.6424 - accuracy: 0.1469\n",
      "Epoch 261/600\n",
      "59/59 - 0s - loss: 3.6205 - accuracy: 0.1474\n",
      "Epoch 262/600\n",
      "59/59 - 0s - loss: 3.5985 - accuracy: 0.1522\n",
      "Epoch 263/600\n",
      "59/59 - 0s - loss: 3.6139 - accuracy: 0.1490\n",
      "Epoch 264/600\n",
      "59/59 - 0s - loss: 3.6178 - accuracy: 0.1496\n",
      "Epoch 265/600\n",
      "59/59 - 0s - loss: 3.5861 - accuracy: 0.1544\n",
      "Epoch 266/600\n",
      "59/59 - 0s - loss: 3.5784 - accuracy: 0.1587\n",
      "Epoch 267/600\n",
      "59/59 - 0s - loss: 3.5683 - accuracy: 0.1613\n",
      "Epoch 268/600\n",
      "59/59 - 0s - loss: 3.5676 - accuracy: 0.1576\n",
      "Epoch 269/600\n",
      "59/59 - 0s - loss: 3.5774 - accuracy: 0.1581\n",
      "Epoch 270/600\n",
      "59/59 - 0s - loss: 3.5624 - accuracy: 0.1619\n",
      "Epoch 271/600\n",
      "59/59 - 0s - loss: 3.5748 - accuracy: 0.1560\n",
      "Epoch 272/600\n",
      "59/59 - 0s - loss: 3.5550 - accuracy: 0.1667\n",
      "Epoch 273/600\n",
      "59/59 - 0s - loss: 3.5621 - accuracy: 0.1672\n",
      "Epoch 274/600\n",
      "59/59 - 0s - loss: 3.5752 - accuracy: 0.1565\n",
      "Epoch 275/600\n",
      "59/59 - 0s - loss: 3.5419 - accuracy: 0.1661\n",
      "Epoch 276/600\n",
      "59/59 - 0s - loss: 3.5777 - accuracy: 0.1576\n",
      "Epoch 277/600\n",
      "59/59 - 0s - loss: 3.6718 - accuracy: 0.1426\n",
      "Epoch 278/600\n",
      "59/59 - 0s - loss: 3.6100 - accuracy: 0.1538\n",
      "Epoch 279/600\n",
      "59/59 - 0s - loss: 3.5509 - accuracy: 0.1613\n",
      "Epoch 280/600\n",
      "59/59 - 0s - loss: 3.5576 - accuracy: 0.1565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/600\n",
      "59/59 - 0s - loss: 3.5362 - accuracy: 0.1640\n",
      "Epoch 282/600\n",
      "59/59 - 0s - loss: 3.5396 - accuracy: 0.1651\n",
      "Epoch 283/600\n",
      "59/59 - 0s - loss: 3.5213 - accuracy: 0.1725\n",
      "Epoch 284/600\n",
      "59/59 - 0s - loss: 3.5547 - accuracy: 0.1608\n",
      "Epoch 285/600\n",
      "59/59 - 0s - loss: 3.5062 - accuracy: 0.1683\n",
      "Epoch 286/600\n",
      "59/59 - 0s - loss: 3.4997 - accuracy: 0.1747\n",
      "Epoch 287/600\n",
      "59/59 - 0s - loss: 3.5043 - accuracy: 0.1704\n",
      "Epoch 288/600\n",
      "59/59 - 0s - loss: 3.4903 - accuracy: 0.1731\n",
      "Epoch 289/600\n",
      "59/59 - 0s - loss: 3.5582 - accuracy: 0.1608\n",
      "Epoch 290/600\n",
      "59/59 - 0s - loss: 3.5162 - accuracy: 0.1693\n",
      "Epoch 291/600\n",
      "59/59 - 0s - loss: 3.5078 - accuracy: 0.1736\n",
      "Epoch 292/600\n",
      "59/59 - 0s - loss: 3.4957 - accuracy: 0.1635\n",
      "Epoch 293/600\n",
      "59/59 - 0s - loss: 3.4845 - accuracy: 0.1715\n",
      "Epoch 294/600\n",
      "59/59 - 0s - loss: 3.4913 - accuracy: 0.1757\n",
      "Epoch 295/600\n",
      "59/59 - 0s - loss: 3.4816 - accuracy: 0.1731\n",
      "Epoch 296/600\n",
      "59/59 - 0s - loss: 3.4538 - accuracy: 0.1763\n",
      "Epoch 297/600\n",
      "59/59 - 0s - loss: 3.4599 - accuracy: 0.1811\n",
      "Epoch 298/600\n",
      "59/59 - 0s - loss: 3.4861 - accuracy: 0.1747\n",
      "Epoch 299/600\n",
      "59/59 - 0s - loss: 3.5034 - accuracy: 0.1651\n",
      "Epoch 300/600\n",
      "59/59 - 0s - loss: 3.6916 - accuracy: 0.1410\n",
      "Epoch 301/600\n",
      "59/59 - 0s - loss: 3.5147 - accuracy: 0.1672\n",
      "Epoch 302/600\n",
      "59/59 - 0s - loss: 3.4580 - accuracy: 0.1757\n",
      "Epoch 303/600\n",
      "59/59 - 0s - loss: 3.4580 - accuracy: 0.1779\n",
      "Epoch 304/600\n",
      "59/59 - 0s - loss: 3.5207 - accuracy: 0.1693\n",
      "Epoch 305/600\n",
      "59/59 - 0s - loss: 3.4843 - accuracy: 0.1731\n",
      "Epoch 306/600\n",
      "59/59 - 0s - loss: 3.4293 - accuracy: 0.1795\n",
      "Epoch 307/600\n",
      "59/59 - 0s - loss: 3.4209 - accuracy: 0.1859\n",
      "Epoch 308/600\n",
      "59/59 - 0s - loss: 3.4688 - accuracy: 0.1795\n",
      "Epoch 309/600\n",
      "59/59 - 0s - loss: 3.4416 - accuracy: 0.1774\n",
      "Epoch 310/600\n",
      "59/59 - 0s - loss: 3.4134 - accuracy: 0.1875\n",
      "Epoch 311/600\n",
      "59/59 - 0s - loss: 3.4070 - accuracy: 0.1832\n",
      "Epoch 312/600\n",
      "59/59 - 0s - loss: 3.4351 - accuracy: 0.1800\n",
      "Epoch 313/600\n",
      "59/59 - 0s - loss: 3.4152 - accuracy: 0.1811\n",
      "Epoch 314/600\n",
      "59/59 - 0s - loss: 3.4182 - accuracy: 0.1811\n",
      "Epoch 315/600\n",
      "59/59 - 0s - loss: 3.4007 - accuracy: 0.1859\n",
      "Epoch 316/600\n",
      "59/59 - 0s - loss: 3.4035 - accuracy: 0.1832\n",
      "Epoch 317/600\n",
      "59/59 - 0s - loss: 3.3974 - accuracy: 0.1811\n",
      "Epoch 318/600\n",
      "59/59 - 0s - loss: 3.3848 - accuracy: 0.1870\n",
      "Epoch 319/600\n",
      "59/59 - 0s - loss: 3.3816 - accuracy: 0.1832\n",
      "Epoch 320/600\n",
      "59/59 - 0s - loss: 3.4115 - accuracy: 0.1811\n",
      "Epoch 321/600\n",
      "59/59 - 0s - loss: 3.4062 - accuracy: 0.1838\n",
      "Epoch 322/600\n",
      "59/59 - 0s - loss: 3.4204 - accuracy: 0.1790\n",
      "Epoch 323/600\n",
      "59/59 - 0s - loss: 3.3816 - accuracy: 0.1864\n",
      "Epoch 324/600\n",
      "59/59 - 0s - loss: 3.3550 - accuracy: 0.1907\n",
      "Epoch 325/600\n",
      "59/59 - 0s - loss: 3.3600 - accuracy: 0.1944\n",
      "Epoch 326/600\n",
      "59/59 - 0s - loss: 3.3522 - accuracy: 0.1886\n",
      "Epoch 327/600\n",
      "59/59 - 0s - loss: 3.3429 - accuracy: 0.1960\n",
      "Epoch 328/600\n",
      "59/59 - 0s - loss: 3.4082 - accuracy: 0.1838\n",
      "Epoch 329/600\n",
      "59/59 - 0s - loss: 3.3758 - accuracy: 0.1832\n",
      "Epoch 330/600\n",
      "59/59 - 0s - loss: 3.3462 - accuracy: 0.1944\n",
      "Epoch 331/600\n",
      "59/59 - 0s - loss: 3.3796 - accuracy: 0.1848\n",
      "Epoch 332/600\n",
      "59/59 - 0s - loss: 3.3437 - accuracy: 0.1971\n",
      "Epoch 333/600\n",
      "59/59 - 0s - loss: 3.3427 - accuracy: 0.1880\n",
      "Epoch 334/600\n",
      "59/59 - 0s - loss: 3.3596 - accuracy: 0.1848\n",
      "Epoch 335/600\n",
      "59/59 - 0s - loss: 3.3584 - accuracy: 0.1864\n",
      "Epoch 336/600\n",
      "59/59 - 0s - loss: 3.3307 - accuracy: 0.1918\n",
      "Epoch 337/600\n",
      "59/59 - 0s - loss: 3.3256 - accuracy: 0.1955\n",
      "Epoch 338/600\n",
      "59/59 - 0s - loss: 3.3438 - accuracy: 0.1907\n",
      "Epoch 339/600\n",
      "59/59 - 0s - loss: 3.3520 - accuracy: 0.1854\n",
      "Epoch 340/600\n",
      "59/59 - 0s - loss: 3.3510 - accuracy: 0.1870\n",
      "Epoch 341/600\n",
      "59/59 - 0s - loss: 3.4106 - accuracy: 0.1790\n",
      "Epoch 342/600\n",
      "59/59 - 0s - loss: 3.3725 - accuracy: 0.1843\n",
      "Epoch 343/600\n",
      "59/59 - 0s - loss: 3.3406 - accuracy: 0.1891\n",
      "Epoch 344/600\n",
      "59/59 - 0s - loss: 3.3385 - accuracy: 0.1918\n",
      "Epoch 345/600\n",
      "59/59 - 0s - loss: 3.3589 - accuracy: 0.1854\n",
      "Epoch 346/600\n",
      "59/59 - 0s - loss: 3.3612 - accuracy: 0.1854\n",
      "Epoch 347/600\n",
      "59/59 - 0s - loss: 3.2820 - accuracy: 0.1960\n",
      "Epoch 348/600\n",
      "59/59 - 0s - loss: 3.2842 - accuracy: 0.1993\n",
      "Epoch 349/600\n",
      "59/59 - 0s - loss: 3.3012 - accuracy: 0.1907\n",
      "Epoch 350/600\n",
      "59/59 - 0s - loss: 3.2763 - accuracy: 0.2009\n",
      "Epoch 351/600\n",
      "59/59 - 0s - loss: 3.2622 - accuracy: 0.2030\n",
      "Epoch 352/600\n",
      "59/59 - 0s - loss: 3.2638 - accuracy: 0.2030\n",
      "Epoch 353/600\n",
      "59/59 - 0s - loss: 3.2561 - accuracy: 0.2094\n",
      "Epoch 354/600\n",
      "59/59 - 0s - loss: 3.2666 - accuracy: 0.2035\n",
      "Epoch 355/600\n",
      "59/59 - 0s - loss: 3.2621 - accuracy: 0.2025\n",
      "Epoch 356/600\n",
      "59/59 - 0s - loss: 3.2753 - accuracy: 0.2003\n",
      "Epoch 357/600\n",
      "59/59 - 0s - loss: 3.2835 - accuracy: 0.1934\n",
      "Epoch 358/600\n",
      "59/59 - 0s - loss: 3.2613 - accuracy: 0.1971\n",
      "Epoch 359/600\n",
      "59/59 - 0s - loss: 3.2314 - accuracy: 0.2073\n",
      "Epoch 360/600\n",
      "59/59 - 0s - loss: 3.2312 - accuracy: 0.2041\n",
      "Epoch 361/600\n",
      "59/59 - 0s - loss: 3.3205 - accuracy: 0.1875\n",
      "Epoch 362/600\n",
      "59/59 - 0s - loss: 3.2622 - accuracy: 0.2014\n",
      "Epoch 363/600\n",
      "59/59 - 0s - loss: 3.2312 - accuracy: 0.2062\n",
      "Epoch 364/600\n",
      "59/59 - 0s - loss: 3.2461 - accuracy: 0.2121\n",
      "Epoch 365/600\n",
      "59/59 - 0s - loss: 3.2438 - accuracy: 0.2035\n",
      "Epoch 366/600\n",
      "59/59 - 0s - loss: 3.2226 - accuracy: 0.2083\n",
      "Epoch 367/600\n",
      "59/59 - 0s - loss: 3.2492 - accuracy: 0.1998\n",
      "Epoch 368/600\n",
      "59/59 - 0s - loss: 3.2123 - accuracy: 0.2083\n",
      "Epoch 369/600\n",
      "59/59 - 0s - loss: 3.2270 - accuracy: 0.2174\n",
      "Epoch 370/600\n",
      "59/59 - 0s - loss: 3.2351 - accuracy: 0.2078\n",
      "Epoch 371/600\n",
      "59/59 - 0s - loss: 3.2027 - accuracy: 0.2137\n",
      "Epoch 372/600\n",
      "59/59 - 0s - loss: 3.2134 - accuracy: 0.2110\n",
      "Epoch 373/600\n",
      "59/59 - 0s - loss: 3.2062 - accuracy: 0.2174\n",
      "Epoch 374/600\n",
      "59/59 - 0s - loss: 3.2130 - accuracy: 0.2110\n",
      "Epoch 375/600\n",
      "59/59 - 0s - loss: 3.2186 - accuracy: 0.2067\n",
      "Epoch 376/600\n",
      "59/59 - 0s - loss: 3.2834 - accuracy: 0.2078\n",
      "Epoch 377/600\n",
      "59/59 - 0s - loss: 3.2802 - accuracy: 0.1912\n",
      "Epoch 378/600\n",
      "59/59 - 0s - loss: 3.3062 - accuracy: 0.1912\n",
      "Epoch 379/600\n",
      "59/59 - 0s - loss: 3.2786 - accuracy: 0.1918\n",
      "Epoch 380/600\n",
      "59/59 - 0s - loss: 3.1941 - accuracy: 0.2062\n",
      "Epoch 381/600\n",
      "59/59 - 0s - loss: 3.1891 - accuracy: 0.2073\n",
      "Epoch 382/600\n",
      "59/59 - 0s - loss: 3.1775 - accuracy: 0.2169\n",
      "Epoch 383/600\n",
      "59/59 - 0s - loss: 3.1685 - accuracy: 0.2217\n",
      "Epoch 384/600\n",
      "59/59 - 0s - loss: 3.1762 - accuracy: 0.2158\n",
      "Epoch 385/600\n",
      "59/59 - 0s - loss: 3.1643 - accuracy: 0.2206\n",
      "Epoch 386/600\n",
      "59/59 - 0s - loss: 3.1884 - accuracy: 0.2147\n",
      "Epoch 387/600\n",
      "59/59 - 0s - loss: 3.1687 - accuracy: 0.2228\n",
      "Epoch 388/600\n",
      "59/59 - 0s - loss: 3.1671 - accuracy: 0.2185\n",
      "Epoch 389/600\n",
      "59/59 - 0s - loss: 3.1370 - accuracy: 0.2254\n",
      "Epoch 390/600\n",
      "59/59 - 0s - loss: 3.1297 - accuracy: 0.2260\n",
      "Epoch 391/600\n",
      "59/59 - 0s - loss: 3.1263 - accuracy: 0.2286\n",
      "Epoch 392/600\n",
      "59/59 - 0s - loss: 3.1520 - accuracy: 0.2174\n",
      "Epoch 393/600\n",
      "59/59 - 0s - loss: 3.1251 - accuracy: 0.2254\n",
      "Epoch 394/600\n",
      "59/59 - 0s - loss: 3.1342 - accuracy: 0.2254\n",
      "Epoch 395/600\n",
      "59/59 - 0s - loss: 3.1544 - accuracy: 0.2185\n",
      "Epoch 396/600\n",
      "59/59 - 0s - loss: 3.1347 - accuracy: 0.2222\n",
      "Epoch 397/600\n",
      "59/59 - 0s - loss: 3.3374 - accuracy: 0.1795\n",
      "Epoch 398/600\n",
      "59/59 - 0s - loss: 3.1769 - accuracy: 0.2147\n",
      "Epoch 399/600\n",
      "59/59 - 0s - loss: 3.1345 - accuracy: 0.2254\n",
      "Epoch 400/600\n",
      "59/59 - 0s - loss: 3.1165 - accuracy: 0.2249\n",
      "Epoch 401/600\n",
      "59/59 - 0s - loss: 3.1776 - accuracy: 0.2121\n",
      "Epoch 402/600\n",
      "59/59 - 0s - loss: 3.2231 - accuracy: 0.1955\n",
      "Epoch 403/600\n",
      "59/59 - 0s - loss: 3.1322 - accuracy: 0.2190\n",
      "Epoch 404/600\n",
      "59/59 - 0s - loss: 3.1261 - accuracy: 0.2265\n",
      "Epoch 405/600\n",
      "59/59 - 0s - loss: 3.1111 - accuracy: 0.2377\n",
      "Epoch 406/600\n",
      "59/59 - 0s - loss: 3.1330 - accuracy: 0.2142\n",
      "Epoch 407/600\n",
      "59/59 - 0s - loss: 3.0891 - accuracy: 0.2388\n",
      "Epoch 408/600\n",
      "59/59 - 0s - loss: 3.0879 - accuracy: 0.2302\n",
      "Epoch 409/600\n",
      "59/59 - 0s - loss: 3.0791 - accuracy: 0.2356\n",
      "Epoch 410/600\n",
      "59/59 - 0s - loss: 3.0825 - accuracy: 0.2345\n",
      "Epoch 411/600\n",
      "59/59 - 0s - loss: 3.0855 - accuracy: 0.2366\n",
      "Epoch 412/600\n",
      "59/59 - 0s - loss: 3.0912 - accuracy: 0.2254\n",
      "Epoch 413/600\n",
      "59/59 - 0s - loss: 3.0742 - accuracy: 0.2286\n",
      "Epoch 414/600\n",
      "59/59 - 0s - loss: 3.0874 - accuracy: 0.2377\n",
      "Epoch 415/600\n",
      "59/59 - 0s - loss: 3.0657 - accuracy: 0.2388\n",
      "Epoch 416/600\n",
      "59/59 - 0s - loss: 3.0619 - accuracy: 0.2292\n",
      "Epoch 417/600\n",
      "59/59 - 0s - loss: 3.0661 - accuracy: 0.2276\n",
      "Epoch 418/600\n",
      "59/59 - 0s - loss: 3.0544 - accuracy: 0.2393\n",
      "Epoch 419/600\n",
      "59/59 - 0s - loss: 3.0957 - accuracy: 0.2329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 420/600\n",
      "59/59 - 0s - loss: 3.1298 - accuracy: 0.2196\n",
      "Epoch 421/600\n",
      "59/59 - 0s - loss: 3.1214 - accuracy: 0.2281\n",
      "Epoch 422/600\n",
      "59/59 - 0s - loss: 3.0614 - accuracy: 0.2340\n",
      "Epoch 423/600\n",
      "59/59 - 0s - loss: 3.0686 - accuracy: 0.2372\n",
      "Epoch 424/600\n",
      "59/59 - 0s - loss: 3.0373 - accuracy: 0.2425\n",
      "Epoch 425/600\n",
      "59/59 - 0s - loss: 3.0251 - accuracy: 0.2463\n",
      "Epoch 426/600\n",
      "59/59 - 0s - loss: 3.0228 - accuracy: 0.2425\n",
      "Epoch 427/600\n",
      "59/59 - 0s - loss: 3.0172 - accuracy: 0.2468\n",
      "Epoch 428/600\n",
      "59/59 - 0s - loss: 3.1039 - accuracy: 0.2238\n",
      "Epoch 429/600\n",
      "59/59 - 0s - loss: 3.0498 - accuracy: 0.2399\n",
      "Epoch 430/600\n",
      "59/59 - 0s - loss: 3.0361 - accuracy: 0.2404\n",
      "Epoch 431/600\n",
      "59/59 - 0s - loss: 3.0576 - accuracy: 0.2340\n",
      "Epoch 432/600\n",
      "59/59 - 0s - loss: 3.1837 - accuracy: 0.2067\n",
      "Epoch 433/600\n",
      "59/59 - 0s - loss: 3.1057 - accuracy: 0.2254\n",
      "Epoch 434/600\n",
      "59/59 - 0s - loss: 3.0438 - accuracy: 0.2340\n",
      "Epoch 435/600\n",
      "59/59 - 0s - loss: 3.0149 - accuracy: 0.2388\n",
      "Epoch 436/600\n",
      "59/59 - 0s - loss: 2.9996 - accuracy: 0.2441\n",
      "Epoch 437/600\n",
      "59/59 - 0s - loss: 3.0257 - accuracy: 0.2441\n",
      "Epoch 438/600\n",
      "59/59 - 0s - loss: 3.0775 - accuracy: 0.2292\n",
      "Epoch 439/600\n",
      "59/59 - 0s - loss: 3.0591 - accuracy: 0.2286\n",
      "Epoch 440/600\n",
      "59/59 - 0s - loss: 3.0529 - accuracy: 0.2361\n",
      "Epoch 441/600\n",
      "59/59 - 0s - loss: 3.1089 - accuracy: 0.2270\n",
      "Epoch 442/600\n",
      "59/59 - 0s - loss: 3.0487 - accuracy: 0.2302\n",
      "Epoch 443/600\n",
      "59/59 - 0s - loss: 3.0302 - accuracy: 0.2436\n",
      "Epoch 444/600\n",
      "59/59 - 0s - loss: 3.0654 - accuracy: 0.2372\n",
      "Epoch 445/600\n",
      "59/59 - 0s - loss: 3.4269 - accuracy: 0.1848\n",
      "Epoch 446/600\n",
      "59/59 - 0s - loss: 3.0614 - accuracy: 0.2302\n",
      "Epoch 447/600\n",
      "59/59 - 0s - loss: 3.0369 - accuracy: 0.2366\n",
      "Epoch 448/600\n",
      "59/59 - 0s - loss: 3.0061 - accuracy: 0.2463\n",
      "Epoch 449/600\n",
      "59/59 - 0s - loss: 3.0123 - accuracy: 0.2318\n",
      "Epoch 450/600\n",
      "59/59 - 0s - loss: 3.0102 - accuracy: 0.2479\n",
      "Epoch 451/600\n",
      "59/59 - 0s - loss: 2.9789 - accuracy: 0.2543\n",
      "Epoch 452/600\n",
      "59/59 - 0s - loss: 2.9643 - accuracy: 0.2580\n",
      "Epoch 453/600\n",
      "59/59 - 0s - loss: 3.0119 - accuracy: 0.2409\n",
      "Epoch 454/600\n",
      "59/59 - 0s - loss: 2.9503 - accuracy: 0.2564\n",
      "Epoch 455/600\n",
      "59/59 - 0s - loss: 2.9839 - accuracy: 0.2548\n",
      "Epoch 456/600\n",
      "59/59 - 0s - loss: 2.9549 - accuracy: 0.2559\n",
      "Epoch 457/600\n",
      "59/59 - 0s - loss: 2.9562 - accuracy: 0.2569\n",
      "Epoch 458/600\n",
      "59/59 - 0s - loss: 2.9465 - accuracy: 0.2591\n",
      "Epoch 459/600\n",
      "59/59 - 0s - loss: 2.9504 - accuracy: 0.2601\n",
      "Epoch 460/600\n",
      "59/59 - 0s - loss: 2.9315 - accuracy: 0.2623\n",
      "Epoch 461/600\n",
      "59/59 - 0s - loss: 2.9239 - accuracy: 0.2612\n",
      "Epoch 462/600\n",
      "59/59 - 0s - loss: 3.0449 - accuracy: 0.2409\n",
      "Epoch 463/600\n",
      "59/59 - 0s - loss: 3.0430 - accuracy: 0.2308\n",
      "Epoch 464/600\n",
      "59/59 - 0s - loss: 2.9491 - accuracy: 0.2580\n",
      "Epoch 465/600\n",
      "59/59 - 0s - loss: 2.9431 - accuracy: 0.2559\n",
      "Epoch 466/600\n",
      "59/59 - 0s - loss: 2.9542 - accuracy: 0.2548\n",
      "Epoch 467/600\n",
      "59/59 - 0s - loss: 2.9628 - accuracy: 0.2505\n",
      "Epoch 468/600\n",
      "59/59 - 0s - loss: 2.9349 - accuracy: 0.2596\n",
      "Epoch 469/600\n",
      "59/59 - 0s - loss: 2.9285 - accuracy: 0.2634\n",
      "Epoch 470/600\n",
      "59/59 - 0s - loss: 2.9309 - accuracy: 0.2655\n",
      "Epoch 471/600\n",
      "59/59 - 0s - loss: 2.9361 - accuracy: 0.2628\n",
      "Epoch 472/600\n",
      "59/59 - 0s - loss: 2.9008 - accuracy: 0.2591\n",
      "Epoch 473/600\n",
      "59/59 - 0s - loss: 2.8988 - accuracy: 0.2804\n",
      "Epoch 474/600\n",
      "59/59 - 0s - loss: 2.9284 - accuracy: 0.2559\n",
      "Epoch 475/600\n",
      "59/59 - 0s - loss: 2.9357 - accuracy: 0.2628\n",
      "Epoch 476/600\n",
      "59/59 - 0s - loss: 2.9027 - accuracy: 0.2644\n",
      "Epoch 477/600\n",
      "59/59 - 0s - loss: 2.9180 - accuracy: 0.2628\n",
      "Epoch 478/600\n",
      "59/59 - 0s - loss: 2.9575 - accuracy: 0.2511\n",
      "Epoch 479/600\n",
      "59/59 - 0s - loss: 2.9161 - accuracy: 0.2650\n",
      "Epoch 480/600\n",
      "59/59 - 0s - loss: 2.9074 - accuracy: 0.2660\n",
      "Epoch 481/600\n",
      "59/59 - 0s - loss: 2.8750 - accuracy: 0.2756\n",
      "Epoch 482/600\n",
      "59/59 - 0s - loss: 2.8574 - accuracy: 0.2879\n",
      "Epoch 483/600\n",
      "59/59 - 0s - loss: 2.8588 - accuracy: 0.2821\n",
      "Epoch 484/600\n",
      "59/59 - 0s - loss: 2.8740 - accuracy: 0.2778\n",
      "Epoch 485/600\n",
      "59/59 - 0s - loss: 2.8862 - accuracy: 0.2687\n",
      "Epoch 486/600\n",
      "59/59 - 0s - loss: 2.8975 - accuracy: 0.2692\n",
      "Epoch 487/600\n",
      "59/59 - 0s - loss: 2.9387 - accuracy: 0.2628\n",
      "Epoch 488/600\n",
      "59/59 - 0s - loss: 2.9090 - accuracy: 0.2703\n",
      "Epoch 489/600\n",
      "59/59 - 0s - loss: 2.9026 - accuracy: 0.2719\n",
      "Epoch 490/600\n",
      "59/59 - 0s - loss: 2.9330 - accuracy: 0.2655\n",
      "Epoch 491/600\n",
      "59/59 - 0s - loss: 3.3835 - accuracy: 0.1875\n",
      "Epoch 492/600\n",
      "59/59 - 0s - loss: 3.6730 - accuracy: 0.1752\n",
      "Epoch 493/600\n",
      "59/59 - 0s - loss: 3.3628 - accuracy: 0.1928\n",
      "Epoch 494/600\n",
      "59/59 - 0s - loss: 3.1615 - accuracy: 0.2099\n",
      "Epoch 495/600\n",
      "59/59 - 0s - loss: 3.0581 - accuracy: 0.2382\n",
      "Epoch 496/600\n",
      "59/59 - 0s - loss: 2.9495 - accuracy: 0.2559\n",
      "Epoch 497/600\n",
      "59/59 - 0s - loss: 2.9203 - accuracy: 0.2585\n",
      "Epoch 498/600\n",
      "59/59 - 0s - loss: 2.8803 - accuracy: 0.2714\n",
      "Epoch 499/600\n",
      "59/59 - 0s - loss: 3.0289 - accuracy: 0.2361\n",
      "Epoch 500/600\n",
      "59/59 - 0s - loss: 2.9430 - accuracy: 0.2559\n",
      "Epoch 501/600\n",
      "59/59 - 0s - loss: 2.8890 - accuracy: 0.2714\n",
      "Epoch 502/600\n",
      "59/59 - 0s - loss: 2.8624 - accuracy: 0.2778\n",
      "Epoch 503/600\n",
      "59/59 - 0s - loss: 2.8631 - accuracy: 0.2751\n",
      "Epoch 504/600\n",
      "59/59 - 0s - loss: 2.8302 - accuracy: 0.2788\n",
      "Epoch 505/600\n",
      "59/59 - 0s - loss: 2.8352 - accuracy: 0.2831\n",
      "Epoch 506/600\n",
      "59/59 - 0s - loss: 2.8287 - accuracy: 0.2837\n",
      "Epoch 507/600\n",
      "59/59 - 0s - loss: 2.8337 - accuracy: 0.2911\n",
      "Epoch 508/600\n",
      "59/59 - 0s - loss: 2.8256 - accuracy: 0.2853\n",
      "Epoch 509/600\n",
      "59/59 - 0s - loss: 2.8460 - accuracy: 0.2746\n",
      "Epoch 510/600\n",
      "59/59 - 0s - loss: 2.8386 - accuracy: 0.2810\n",
      "Epoch 511/600\n",
      "59/59 - 0s - loss: 2.8241 - accuracy: 0.2874\n",
      "Epoch 512/600\n",
      "59/59 - 0s - loss: 2.8133 - accuracy: 0.2895\n",
      "Epoch 513/600\n",
      "59/59 - 0s - loss: 2.8217 - accuracy: 0.2869\n",
      "Epoch 514/600\n",
      "59/59 - 0s - loss: 2.8500 - accuracy: 0.2810\n",
      "Epoch 515/600\n",
      "59/59 - 0s - loss: 3.0023 - accuracy: 0.2505\n",
      "Epoch 516/600\n",
      "59/59 - 0s - loss: 2.8443 - accuracy: 0.2783\n",
      "Epoch 517/600\n",
      "59/59 - 0s - loss: 2.8098 - accuracy: 0.2869\n",
      "Epoch 518/600\n",
      "59/59 - 0s - loss: 2.9168 - accuracy: 0.2682\n",
      "Epoch 519/600\n",
      "59/59 - 0s - loss: 3.0286 - accuracy: 0.2382\n",
      "Epoch 520/600\n",
      "59/59 - 0s - loss: 2.8591 - accuracy: 0.2719\n",
      "Epoch 521/600\n",
      "59/59 - 0s - loss: 2.8513 - accuracy: 0.2821\n",
      "Epoch 522/600\n",
      "59/59 - 0s - loss: 2.8263 - accuracy: 0.2837\n",
      "Epoch 523/600\n",
      "59/59 - 0s - loss: 2.8158 - accuracy: 0.2874\n",
      "Epoch 524/600\n",
      "59/59 - 0s - loss: 2.8227 - accuracy: 0.2831\n",
      "Epoch 525/600\n",
      "59/59 - 0s - loss: 2.7893 - accuracy: 0.2970\n",
      "Epoch 526/600\n",
      "59/59 - 0s - loss: 2.8542 - accuracy: 0.2783\n",
      "Epoch 527/600\n",
      "59/59 - 0s - loss: 2.8184 - accuracy: 0.2810\n",
      "Epoch 528/600\n",
      "59/59 - 0s - loss: 2.7921 - accuracy: 0.2879\n",
      "Epoch 529/600\n",
      "59/59 - 0s - loss: 2.7736 - accuracy: 0.2890\n",
      "Epoch 530/600\n",
      "59/59 - 0s - loss: 2.7645 - accuracy: 0.3002\n",
      "Epoch 531/600\n",
      "59/59 - 0s - loss: 2.7646 - accuracy: 0.3002\n",
      "Epoch 532/600\n",
      "59/59 - 0s - loss: 2.7807 - accuracy: 0.2965\n",
      "Epoch 533/600\n",
      "59/59 - 0s - loss: 2.8108 - accuracy: 0.2847\n",
      "Epoch 534/600\n",
      "59/59 - 0s - loss: 2.7793 - accuracy: 0.2917\n",
      "Epoch 535/600\n",
      "59/59 - 0s - loss: 2.7508 - accuracy: 0.2927\n",
      "Epoch 536/600\n",
      "59/59 - 0s - loss: 2.7540 - accuracy: 0.2997\n",
      "Epoch 537/600\n",
      "59/59 - 0s - loss: 2.7529 - accuracy: 0.2981\n",
      "Epoch 538/600\n",
      "59/59 - 0s - loss: 2.8707 - accuracy: 0.2751\n",
      "Epoch 539/600\n",
      "59/59 - 0s - loss: 2.8453 - accuracy: 0.2719\n",
      "Epoch 540/600\n",
      "59/59 - 0s - loss: 2.8457 - accuracy: 0.2842\n",
      "Epoch 541/600\n",
      "59/59 - 0s - loss: 2.9371 - accuracy: 0.2628\n",
      "Epoch 542/600\n",
      "59/59 - 0s - loss: 2.9018 - accuracy: 0.2660\n",
      "Epoch 543/600\n",
      "59/59 - 0s - loss: 2.8060 - accuracy: 0.2863\n",
      "Epoch 544/600\n",
      "59/59 - 0s - loss: 2.7893 - accuracy: 0.2970\n",
      "Epoch 545/600\n",
      "59/59 - 0s - loss: 2.7663 - accuracy: 0.2986\n",
      "Epoch 546/600\n",
      "59/59 - 0s - loss: 2.7682 - accuracy: 0.2954\n",
      "Epoch 547/600\n",
      "59/59 - 0s - loss: 2.7861 - accuracy: 0.2895\n",
      "Epoch 548/600\n",
      "59/59 - 0s - loss: 2.7638 - accuracy: 0.2965\n",
      "Epoch 549/600\n",
      "59/59 - 0s - loss: 2.7357 - accuracy: 0.3045\n",
      "Epoch 550/600\n",
      "59/59 - 0s - loss: 2.7096 - accuracy: 0.3152\n",
      "Epoch 551/600\n",
      "59/59 - 0s - loss: 2.7136 - accuracy: 0.3082\n",
      "Epoch 552/600\n",
      "59/59 - 0s - loss: 2.7210 - accuracy: 0.3184\n",
      "Epoch 553/600\n",
      "59/59 - 0s - loss: 2.7301 - accuracy: 0.3045\n",
      "Epoch 554/600\n",
      "59/59 - 0s - loss: 2.7350 - accuracy: 0.3093\n",
      "Epoch 555/600\n",
      "59/59 - 0s - loss: 2.7217 - accuracy: 0.3072\n",
      "Epoch 556/600\n",
      "59/59 - 0s - loss: 2.7227 - accuracy: 0.3104\n",
      "Epoch 557/600\n",
      "59/59 - 0s - loss: 2.7835 - accuracy: 0.2874\n",
      "Epoch 558/600\n",
      "59/59 - 0s - loss: 2.7449 - accuracy: 0.2991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 559/600\n",
      "59/59 - 0s - loss: 2.7388 - accuracy: 0.2991\n",
      "Epoch 560/600\n",
      "59/59 - 0s - loss: 2.7356 - accuracy: 0.3034\n",
      "Epoch 561/600\n",
      "59/59 - 0s - loss: 2.7290 - accuracy: 0.3018\n",
      "Epoch 562/600\n",
      "59/59 - 0s - loss: 2.7103 - accuracy: 0.3130\n",
      "Epoch 563/600\n",
      "59/59 - 0s - loss: 2.7078 - accuracy: 0.3141\n",
      "Epoch 564/600\n",
      "59/59 - 0s - loss: 2.7716 - accuracy: 0.2981\n",
      "Epoch 565/600\n",
      "59/59 - 0s - loss: 2.7562 - accuracy: 0.2981\n",
      "Epoch 566/600\n",
      "59/59 - 0s - loss: 2.7054 - accuracy: 0.3125\n",
      "Epoch 567/600\n",
      "59/59 - 0s - loss: 2.6985 - accuracy: 0.3173\n",
      "Epoch 568/600\n",
      "59/59 - 0s - loss: 2.7377 - accuracy: 0.2981\n",
      "Epoch 569/600\n",
      "59/59 - 0s - loss: 2.7281 - accuracy: 0.3072\n",
      "Epoch 570/600\n",
      "59/59 - 0s - loss: 2.7509 - accuracy: 0.3013\n",
      "Epoch 571/600\n",
      "59/59 - 0s - loss: 2.9834 - accuracy: 0.2634\n",
      "Epoch 572/600\n",
      "59/59 - 0s - loss: 3.2215 - accuracy: 0.2228\n",
      "Epoch 573/600\n",
      "59/59 - 0s - loss: 3.0273 - accuracy: 0.2521\n",
      "Epoch 574/600\n",
      "59/59 - 0s - loss: 2.9266 - accuracy: 0.2543\n",
      "Epoch 575/600\n",
      "59/59 - 0s - loss: 2.7606 - accuracy: 0.2885\n",
      "Epoch 576/600\n",
      "59/59 - 0s - loss: 2.7732 - accuracy: 0.2954\n",
      "Epoch 577/600\n",
      "59/59 - 0s - loss: 2.7335 - accuracy: 0.3024\n",
      "Epoch 578/600\n",
      "59/59 - 0s - loss: 2.8649 - accuracy: 0.2735\n",
      "Epoch 579/600\n",
      "59/59 - 0s - loss: 2.8551 - accuracy: 0.2783\n",
      "Epoch 580/600\n",
      "59/59 - 0s - loss: 2.8236 - accuracy: 0.2740\n",
      "Epoch 581/600\n",
      "59/59 - 0s - loss: 2.7281 - accuracy: 0.3013\n",
      "Epoch 582/600\n",
      "59/59 - 0s - loss: 2.7114 - accuracy: 0.3125\n",
      "Epoch 583/600\n",
      "59/59 - 0s - loss: 2.6895 - accuracy: 0.3088\n",
      "Epoch 584/600\n",
      "59/59 - 0s - loss: 2.6998 - accuracy: 0.3125\n",
      "Epoch 585/600\n",
      "59/59 - 0s - loss: 2.7204 - accuracy: 0.3061\n",
      "Epoch 586/600\n",
      "59/59 - 0s - loss: 2.7016 - accuracy: 0.3045\n",
      "Epoch 587/600\n",
      "59/59 - 0s - loss: 2.6718 - accuracy: 0.3189\n",
      "Epoch 588/600\n",
      "59/59 - 0s - loss: 2.7011 - accuracy: 0.3162\n",
      "Epoch 589/600\n",
      "59/59 - 0s - loss: 2.6636 - accuracy: 0.3226\n",
      "Epoch 590/600\n",
      "59/59 - 0s - loss: 2.6689 - accuracy: 0.3114\n",
      "Epoch 591/600\n",
      "59/59 - 0s - loss: 2.6530 - accuracy: 0.3243\n",
      "Epoch 592/600\n",
      "59/59 - 0s - loss: 2.6542 - accuracy: 0.3205\n",
      "Epoch 593/600\n",
      "59/59 - 0s - loss: 2.6585 - accuracy: 0.3237\n",
      "Epoch 594/600\n",
      "59/59 - 0s - loss: 2.6431 - accuracy: 0.3243\n",
      "Epoch 595/600\n",
      "59/59 - 0s - loss: 2.6462 - accuracy: 0.3339\n",
      "Epoch 596/600\n",
      "59/59 - 0s - loss: 2.7147 - accuracy: 0.3130\n",
      "Epoch 597/600\n",
      "59/59 - 0s - loss: 2.7579 - accuracy: 0.3098\n",
      "Epoch 598/600\n",
      "59/59 - 0s - loss: 2.7747 - accuracy: 0.2927\n",
      "Epoch 599/600\n",
      "59/59 - 0s - loss: 2.7162 - accuracy: 0.2997\n",
      "Epoch 600/600\n",
      "59/59 - 0s - loss: 2.7023 - accuracy: 0.3061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcace6c0880>"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(train_X, one_hot_y, epochs=600, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "89bd4977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result 0.28800000000000003\n",
      "real value 0.20299999999999999\n"
     ]
    }
   ],
   "source": [
    "umm = 16\n",
    "result = model_2.predict_classes([test_X[umm].tolist()])\n",
    "print(\"result\",y[result[0]])\n",
    "print(\"real value\", test_y[umm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "79c1225f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "3e1c476b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        1,  6, 12,  3, 47, 36, 65, 64, 41, 50, 62])"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d267b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "30efc560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0]])"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "6e843a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22899999999999998"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "c3adc513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3808318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
